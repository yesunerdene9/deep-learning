{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1b5a64f",
      "metadata": {
        "id": "d1b5a64f"
      },
      "source": [
        "# Deep Learning course Project Assignment\n",
        "### Test Time Adaptation\n",
        "\n",
        "Yesun-Erdene Jargalsaikhan [247523], y.jargalsaikhan@studenti.unitn.it\n",
        "\n",
        "18 June, 2025\n",
        "\n",
        "Quick Access:\n",
        "1. [Introduction](#introduction)  \n",
        "   1.1 [Test Time Adaptation](#memo)  \n",
        "   1.2 [MEMO](#augmentation-techniques)  \n",
        "   1.3 [Marginal Entropy Minimization with One test point](#marginal-entropy-minimization-with-one-test-point)  \n",
        "   1.4 [My modifications](#my-modifications)  \n",
        "   1.5 [Instruction for running experiments ⬇️](#instruction-for-running-experiments)\n",
        "\n",
        "2. [Implementation](#implementation)     \n",
        "   2.1 [MEMO re-implementation](#memo-re-implementation)  \n",
        "   2.2 [Entropy Loss](#entroty-loss).  \n",
        "      2.2.1  [Marginal Entropy Loss with Sharpened Softmax](#marginal-entropy-loss-with-sharpened-softmax)   \n",
        "      2.2.2  [Augmentation-Weighted Entropy](#augmentation-weighted-entropy)   \n",
        "   2.3 [Dataset for the domain shift challenge](#dataset-for-the-domain-shift-challenge)  \n",
        "\n",
        "3. [Preparation for the experiments](#preparation-for-experiments)  \n",
        "    3.1 [Pre-trained models](#pre-trained-models)   \n",
        "    3.3 [Test functions](#test-functions)\n",
        "\n",
        "4. [Experiments](#experiments)  \n",
        "   4.1 [Baselines](#baselines)  \n",
        "   4.2 [TTA applied](#tta-applied)\n",
        "\n",
        "5. [Results](#results)   \n",
        "   5.1 [Discussion](#discussion)  \n",
        "   5.2 [Conclusion](#Conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f1adcfa",
      "metadata": {
        "id": "3f1adcfa"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4f0952",
      "metadata": {
        "id": "fb4f0952"
      },
      "source": [
        "\n",
        "In this project I re-implemented MEMO (Marginal Entropy Minimization with One test point) to improve the performance of the pre-trained model on image classification task at a test time. The purpose of the project is to adapt the model to perform better when the test data distribution differs from the distribution of the dataset it was originally trained on.\n",
        "\n",
        "\n",
        "#### Test Time Adaptation\n",
        "\n",
        "For domain shift challenges in image classification, this adaptation technique improves performance of the pre-trained model on test dataset that are visually different by without accessing to the labels of the samples and one at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342b8d80",
      "metadata": {
        "id": "342b8d80",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### MEMO\n",
        "\n",
        "**Test Time Robustness via Adaptation and Augmentation** [Zhang et al. (2021)](https://arxiv.org/abs/2110.09506)\n",
        "\n",
        "The approach proposed a simple method that modifies how the inference is done without assumption on training process or test time data availabbility, and can be used by model that is probabilistic and adaptable.\n",
        "\n",
        "MEMO performs set of different augmentations on the test sample independently, and takes the conditional output distribution from the pre-trained model as the output for each augmentented version of the image, then computes the marginal distribution by averaging the conditional output distributions, and computes marginal entropy of the marginal distribution and minimize it. And this adapts the model parameters for each test sample to ensure predict same label accross augmented images (invariant to augmentations) and increase the confidence of the model. Finally the adapted model can then make its final prediction on the clean test point rather than the augmented copies.\n",
        "\n",
        "Only minimizing the entropy of the conditional probability distribions is asking just the model to be confident in it's prediction regardless of the  output correctness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af6cdad",
      "metadata": {
        "id": "7af6cdad"
      },
      "source": [
        "#### Marginal Entropy Minimization with One test point\n",
        "\n",
        "**Image classification**\n",
        "\n",
        "The task of image classification — predicts category of an image, prediction $\\widehat{y}$  is label the image belongs to, computes probability distribution over the set of classes which gives conditional probability distribution over the set of classes given the input and weights, and the label is given the argmax over the probability distirbution\n",
        "\n",
        "$$\n",
        "\\widehat{y} = M(x \\mid W) = \\arg\\max_{y \\in Y} \\, p(y \\mid x, W)\n",
        "$$\n",
        "\n",
        "\n",
        "<div align=\"center\">where $M$ trained model, $W$ weight space, $X$ input space, $Y$ output space, $w \\in W, x \\in X, y \\in Y$ corresponding variables</div>\n",
        "\n",
        "\n",
        "\n",
        "**Augmentation**\n",
        "\n",
        "- $A = \\{ a_1, a_2, \\ldots, a_K \\}$: set of $K$ augmentations. <br>\n",
        "- $x_k = a_k(\\mathbf{x})$: the $k$-th augmented input. <br>\n",
        "- $p_W(y \\mid x_k) = M_W(x_k)$: model's conditional output distribution for augmented input.\n",
        "\n",
        "\n",
        "**Marginal Distribution**\n",
        "\n",
        "Marginal distribution is computed by averaging the conditional output distributions over the augmented versions of single text input.\n",
        "\n",
        "$$\n",
        "\\bar{p}_W(y \\mid \\mathbf{x}) = \\frac{1}{K} \\sum_{k=1}^{K} p_W(y \\mid x_k)\n",
        "$$\n",
        "\n",
        "\n",
        "**Entropy**\n",
        "\n",
        "We need to measure the confidence of the classifier in the prediction, considering there is no access to the label. Entropy measures uncertainty in a probability distribution: the higher the entropy, the less confidence there is; the lower the entropy, the higher the confidence in the classifier.\n",
        "\n",
        "$$\n",
        "H(p) = - \\sum_{i=1}^{C} p_i \\log p_i\n",
        "$$\n",
        "\n",
        "\n",
        " >  &nbsp;&nbsp;&nbsp;&nbsp;**Marginal Entropy** <br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;Marginal entropy is computed as the entropy of the marginal distribution, representing the model's overall uncertainty.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;$$\n",
        "H(\\bar{p}_W(y \\mid x)) = - \\sum_{c=1}^{C} \\bar{p}_W(y = c \\mid x) \\log \\bar{p}_W(y = c \\mid x)\n",
        "$$\n",
        "\n",
        "\n",
        "<div align=\"center\">where $C$ is the number of output classes.</div>\n",
        "\n",
        "\n",
        "**Minimization of the entropy**\n",
        "\n",
        "Through training iteration and objective function, the confidence of the model will get higher towards a given class, and the probabilities associated with other classes will go down. So that the model gets more confident. One issue is that misprediction will be amplified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GhfOULMCYfT6",
      "metadata": {
        "id": "GhfOULMCYfT6"
      },
      "source": [
        "### My modifications"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hmWtBFonYmgc",
      "metadata": {
        "id": "hmWtBFonYmgc"
      },
      "source": [
        "The experiment results of each modification are discussed in the [discussion part](#discussion).\n",
        "\n",
        "#### Adaptive batch normalization\n",
        "\n",
        "As the MEMO paper suggested that adaptive batch normalization on the model improved the performance, I also brought it as a modification to the model, and applied it also for all the subsequent modifications\n",
        "\n",
        "#### Different ways to compute the marginal Entropy\n",
        "\n",
        "Since one of the objective is to increase the confidence of the model in it's prediction, I decided to modify the method of computing the entropy to make it more robust to different version of augmentations. With this reason I implemented following methods:\n",
        "\n",
        "- **Sharpened softmax marginal entropy**\n",
        "\n",
        "The motivation is inspired by the work [Veličković et al. (2025)](https://arxiv.org/abs/2410.01104), which proposed an adaptive temperature technique as an ad-hoc technique for improving the sharpness of softmax at inference. The detail can be found in the dedicated [cell here](#marginal-entropy-loss-with-sharpened-softmax).\n",
        "\n",
        "- **Augmentation weighted marginal entropy**\n",
        "\n",
        "The motivation has come from the idea that not all augmentations are useful, so weighting the entropy contribution from each augmentation. Weighted marginal entropy loss, where the weights are based on the model’s confidence (max softmax probability) for each augmentation. The detail can be found in the dedicated [cell here](#marginal-entropy-loss-with-weighted-augmentation).\n",
        "\n",
        "\n",
        "#### Different choices of augmentation methods\n",
        "\n",
        "Regarding the condition that he distribution of the dataset is different than the original, also having only one test example at a time, it's obliged to use data augmentation method to improve the model's performace. Therefore, for choosig the augmentation method, I tried to following the MEMO experiments, and chose another combination of augmentation methods to improve the model's performace.\n",
        "\n",
        "- **RandomResizedCrop**\n",
        "\n",
        "As the MEMO paper suggested, the RandomResizedCrop method was used in their experiments, I conducted the experiments mostly with this augmentation method.\n",
        "\n",
        "- **RandomResizedCrop + RandomHorizontalFlip**\n",
        "\n",
        "I chose the combination of the two methods because the MEMO paper has witnessed the improvement using the horizontal flip standard augmentation method.\n",
        "\n",
        "- **RandomResizedCrop + RandomAffine + RandomPerspective + RandomHorizontalFlip**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lGsSeHvWz4Cz",
      "metadata": {
        "id": "lGsSeHvWz4Cz"
      },
      "source": [
        "### Instructions for running experiments\n",
        "‼️\n",
        "\n",
        "*   If the reader must run the experiment on ***Google Colab***, please set the variable $IS\\_COLAB$ to $True$ in the first Preparation cell\n",
        "    *   The dataset needs to be present in the reader's Google Drive, and please change the image root variables as well\n",
        "*   If the reader must run the experiment on ***AWS***, please set the variable $IS\\_COLAB$ to $False$ in the first Preparation cell\n",
        "    *   The dataset is uploaded to usergroup-49, and there is no need to change directories; only the notebook needs to be in one directory. If necessary, please adjust the image root variable to suit your environment.\n",
        "    *   Uncomment lines in the 2nd cell if needed to place the dataset in the desired directory\n",
        "\n",
        "*   Each experiment is allocated in on single cell, so that it's convinient for the reader if need to test experiments ([here](#experiments)).\n",
        "\n",
        "If anything needs clarification, please send an email to me."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RtP6EC46NBd-",
      "metadata": {
        "id": "RtP6EC46NBd-"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cca31e9d",
      "metadata": {
        "id": "cca31e9d",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "po2ierZ7Uqpz",
      "metadata": {
        "id": "po2ierZ7Uqpz"
      },
      "outputs": [],
      "source": [
        "# --- Change it into True if need to run in colab (but need to have the dataset in colab too) -----#\n",
        "IS_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ax7BI1YeHV4n",
      "metadata": {
        "id": "ax7BI1YeHV4n"
      },
      "outputs": [],
      "source": [
        "# --- Uncomment following lines if need to place the dataset in desired directory -----#\n",
        "\n",
        "# extract dataset if needed (in aws)\n",
        "# !tar -xf datasets/ImageNet-A/imagenet-a.tar\n",
        "# !tar -xf datasets/ImageNet-V2/imagenetv2-matched-frequency.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb6e960",
      "metadata": {
        "id": "3bb6e960",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# --- Uncomment and run the following lines if error related to torch happens -----#\n",
        "\n",
        "# !pip uninstall -y torch torchvision\n",
        "# %pip install torch torchvision\n",
        "# %pip install ftfy regex tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3af7fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d3af7fa",
        "outputId": "e1fc3c6b-49db-483a-f0a5-30ef0d39f8ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-18 10:10:16.565174: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-18 10:10:16.713426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750241416.735421    1305 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750241416.744249    1305 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-18 10:10:16.838445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import types\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Considering TTA, one input prediction at a time\n",
        "DEFAULT_BATCH_SIZE = 1\n",
        "\n",
        "# chosen from the MEMO paper\n",
        "NUM_AUGMENTATION = 32\n",
        "\n",
        "# prior strength number for adaptive batch normalization\n",
        "PRIOR_STRENGTH = 16\n",
        "\n",
        "# prior strength number for adaptive batch normalization\n",
        "TEMPERATURE = 0.5\n",
        "\n",
        "# device where the computation should take place\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# if running in COLAB, please change the path according to your dataset path\n",
        "if IS_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive/\")\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/DL' # change the path if needed\n",
        "    os.chdir(path)\n",
        "\n",
        "# defining image root for datasets\n",
        "if IS_COLAB:\n",
        "    im_groot_imagenet_a = \"/content/drive/MyDrive/Colab Notebooks/DL/datasets/ImageNet-A/imagenet-a\"\n",
        "    im_groot_imagenet_v2 = \"/content/drive/MyDrive/Colab Notebooks/DL/datasets/ImageNet-V2/imagenetv2-matched-frequency-format-val\"\n",
        "else: # in aws, I added the datasets in aws\n",
        "    im_groot_imagenet_a = \"../datasets/ImageNet-A/imagenet-a/\"\n",
        "    im_groot_imagenet_v2 = \"../datasets/ImageNet-V2/imagenetv2-matched-frequency-format-val/\"\n",
        "\n",
        "\n",
        "# Logger for saving the experiment result\n",
        "logger = logging.getLogger('my_test_logger')\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c83d0f",
      "metadata": {
        "id": "d9c83d0f"
      },
      "source": [
        "### Memo re-implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UIuL14nsCFDE",
      "metadata": {
        "id": "UIuL14nsCFDE"
      },
      "source": [
        "#### MEMO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y70qCnWjCArp",
      "metadata": {
        "id": "Y70qCnWjCArp"
      },
      "outputs": [],
      "source": [
        "# https://github.com/bethgelab/robustness/blob/main/robusta/batchnorm/bn.py#L175\n",
        "def _modified_bn_forward(self, input):\n",
        "    est_mean = torch.zeros(self.running_mean.shape, device=self.running_mean.device)\n",
        "    est_var = torch.ones(self.running_var.shape, device=self.running_var.device)\n",
        "    nn.functional.batch_norm(input, est_mean, est_var, None, None, True, 1.0, self.eps)\n",
        "    running_mean = self.prior * self.running_mean + (1 - self.prior) * est_mean\n",
        "    running_var = self.prior * self.running_var + (1 - self.prior) * est_var\n",
        "    return nn.functional.batch_norm(input, running_mean, running_var, self.weight, self.bias, False, 0, self.eps)\n",
        "\n",
        "class MEMO(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A class for neurol network for the reimplementation of MEMO for test time adaptation method\n",
        "    Args:\n",
        "        model:                model\n",
        "        learning_rate:        learning rate which used for adapting the model during test time\n",
        "        optimizer:            optimizer used during test time\n",
        "        loss_function:        loss function\n",
        "        label_mask:           label_mask\n",
        "        apply_tta:            whether to apply TTA during test time\n",
        "        augmentations:        sef of augmentations\n",
        "        prior_strenght_bn:    prior_strenght_bn\n",
        "        apply_adaptive_bn:    wether to apply adaptive BN\n",
        "        temperature:          temperature\n",
        "        apply_transform:      apply_transform\n",
        "        preprocess:           preprocess\n",
        "        device:               device\n",
        "        number_of_augmentation: number of augmentation to generate (will be the intermediate batch size for test time adapting)\n",
        "    Other\n",
        "        initial_configuration : initial configuration of the model, before analysing each new smaple, the state of the network should be reset to initial\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 learning_rate,\n",
        "                 optimizer,\n",
        "                 loss_function,\n",
        "                 label_mask,\n",
        "                 apply_tta = True,\n",
        "                 augmentations = None,\n",
        "                 prior_strenght_bn = None,\n",
        "                 apply_adaptive_bn = False,\n",
        "                 temperature = None,\n",
        "                 apply_transform = False,\n",
        "                 preprocess = None,\n",
        "                 device=device,\n",
        "                 number_of_augmentation=NUM_AUGMENTATION):\n",
        "        super(MEMO, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "        self.apply_tta = apply_tta\n",
        "        self.label_mask = label_mask\n",
        "        self.model = model.to(device)\n",
        "        self.loss_function = loss_function\n",
        "        self.temperature = temperature\n",
        "        self.augmentations = augmentations\n",
        "        self.learning_rate = learning_rate\n",
        "        self.apply_transform = apply_transform\n",
        "        self.prior_strenght_bn = prior_strenght_bn\n",
        "        self.apply_adaptive_bn = apply_adaptive_bn\n",
        "        self.preprocess = preprocess\n",
        "        self.number_of_augmentation = number_of_augmentation\n",
        "        self.initial_configuration = deepcopy(self.model.state_dict())\n",
        "\n",
        "        # apply the batch normalization if switch parameters is True\n",
        "        if apply_adaptive_bn == True:\n",
        "            nn.BatchNorm2d.prior = 1.0\n",
        "            nn.BatchNorm2d.forward = _modified_bn_forward\n",
        "            for module in self.model.modules():\n",
        "                # That globally overrides BatchNorm everywhere in PyTorch,\n",
        "                # which may affect other models or modules unintentionally.\n",
        "                if isinstance(module, nn.BatchNorm2d):\n",
        "                    module.forward = types.MethodType(_modified_bn_forward, module)\n",
        "\n",
        "    def augment_image(self, x):\n",
        "        \"\"\"\n",
        "        Applies augmentation choices on image the number of augmentation times\n",
        "\n",
        "        Returns: list of augmented versions of input image including the original input image\n",
        "\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            augmented_images = []\n",
        "            # augmented_images.append(x)\n",
        "\n",
        "            for _ in range(self.number_of_augmentation):\n",
        "                aug_img = self.augmentations(x)  # always apply transforms\n",
        "                if not isinstance(aug_img, torch.Tensor):\n",
        "                    aug_img = to_tensor(aug_img)\n",
        "                augmented_images.append(aug_img)\n",
        "\n",
        "            inputs = torch.stack(augmented_images).to(self.device)\n",
        "\n",
        "            return inputs\n",
        "\n",
        "    def test_time_adaptation(self, x):\n",
        "        \"\"\"\n",
        "        This function implements the MEMO approach:\n",
        "            1. Augment the image\n",
        "            2. Compute the marginal distribution\n",
        "            3. Compute the entropy and minimize the entropy\n",
        "            4. Predict the original input with the updated model\n",
        "\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "\n",
        "        # Set the network to evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Load the model to device to do computation (GPU)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # reset prediction variable\n",
        "        predictions = None\n",
        "\n",
        "        if self.prior_strenght_bn is None:\n",
        "            nn.BatchNorm2d.prior = 1\n",
        "        else:\n",
        "            nn.BatchNorm2d.prior = float(self.prior_strenght_bn) / float(self.prior_strenght_bn + 1)\n",
        "\n",
        "        for image in x:\n",
        "            # Reset the gradient\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Get the augmented variants of the image\n",
        "            inputs = self.augment_image(image)\n",
        "\n",
        "            # First forward pass and take the logits\n",
        "            outputs = self.model(inputs)\n",
        "\n",
        "            # Compute the entropy loss\n",
        "            if self.temperature is None:\n",
        "                loss = self.loss_function(outputs)\n",
        "            else:\n",
        "                # if temperatutre is given, pass to the loss function with the temperature parameter\n",
        "                loss = self.loss_function(outputs, self.temperature)\n",
        "\n",
        "            # Compute the gradient\n",
        "            loss.backward()\n",
        "\n",
        "            # Parameters update\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Predict the original input with the updated model\n",
        "            if self.apply_transform == False:\n",
        "                prediction = self.model(x)\n",
        "                prediction = prediction[:, self.label_mask]\n",
        "            else:\n",
        "                # applies prepocess, as preprocess of the base model has not done on the image\n",
        "                original_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "                prediction = self.model(original_input)\n",
        "                prediction = prediction[:, self.label_mask]\n",
        "\n",
        "            # Reset the model parameters to initial\n",
        "            self.model.load_state_dict(deepcopy(self.initial_configuration))\n",
        "\n",
        "        # reset the prior back to 1\n",
        "        nn.BatchNorm2d.prior = 1\n",
        "\n",
        "        return prediction\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "        \"\"\"\n",
        "        if self.apply_tta:\n",
        "            return self.test_time_adaptation(x)\n",
        "        else:\n",
        "            output = self.model(x)\n",
        "            output = output[:, self.label_mask]\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c71f116",
      "metadata": {
        "id": "9c71f116",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Entropy Loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L27FxuSyUi98",
      "metadata": {
        "id": "L27FxuSyUi98"
      },
      "source": [
        "##### Marginal Entropy Loss\n",
        "\n",
        "As the MEMO paper implemented, marginal entropy loss is computed on the marginal distribution which is the average of conditional output distribution over the augmented versions of the single input.\n",
        "y is already a probability as softmax is applied\n",
        "\n",
        "$$\n",
        "\\bar{p}_W(y \\mid \\mathbf{x}) = \\frac{1}{K} \\sum_{k=1}^{K} p_W(y \\mid x_k)\n",
        "$$\n",
        "\n",
        "$$\n",
        "H(\\bar{p}_W(y \\mid x)) = - \\sum_{c=1}^{C} \\bar{p}_W(y = c \\mid x) \\log \\bar{p}_W(y = c \\mid x)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "where:\n",
        "- $K$ is the number of augmentations\n",
        "- $C$ is the number of classes\n",
        "- $\\bar{p}_W(y = c \\mid x)$ is marginal prediction after averaging softmax over augmentations\n",
        "- $H(⋅)$ is entropy of the marginal prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d657e6a7",
      "metadata": {
        "id": "d657e6a7"
      },
      "outputs": [],
      "source": [
        "def marginal_entropy_loss(logits):\n",
        "    # Apply softmax to get probability distribution\n",
        "    probabilities = F.softmax(logits, dim=1)\n",
        "\n",
        "    # Compute marginal distribution averaged over the outputs of augmentations\n",
        "    marginal_outputs = probabilities.mean(dim=0)\n",
        "\n",
        "    # Compute the entropy of the marginal output\n",
        "    marginal_entropy = -torch.sum(marginal_outputs * torch.log(marginal_outputs))\n",
        "\n",
        "    return marginal_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jbfDn_4OoT-e",
      "metadata": {
        "id": "jbfDn_4OoT-e"
      },
      "source": [
        "##### Marginal Entropy Loss with Sharpened Softmax\n",
        "\n",
        "The motivation is inspired by the work [Veličković et al. (2025)](https://arxiv.org/abs/2410.01104), which proposed an adaptive temperature technique as an ad-hoc technique for improving the sharpness of softmax at inference time for overcoming the fundamental limitation of softmax that arises as the number of items grows at test time. The main suggestion from the work is that softmax loses sharpness (low-entropy decision boundary) on out-of-distribution (OOD) inputs, which, in my case, can be grounded to distribution variation. Therefore, need to dynamically lower the softmax temperature at inference time (“adaptive temperature”), by making $T$ smaller for larger or more difficult inputs, sharpen the softmax, leading towards a lower-entropy, however in my case I decided to keep the $T$ as fixed rather than dynamically degrading the value:\n",
        "\n",
        "$$\n",
        "\\bar{p}_W(y = c \\mid x) = \\frac{1}{K} \\sum_{k=1}^{K} \\text{Softmax}\\left( \\frac{z^{(k)}}{T} \\right)_c\n",
        "$$\n",
        "\n",
        "$$\n",
        "H(\\bar{p}_W(y \\mid x)) = - \\sum_{c=1}^{C} \\bar{p}_W(y = c \\mid x) \\log \\bar{p}_W(y = c \\mid x)\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $K$ is the number of augmentations\n",
        "- $C$ is the number of classes\n",
        "- $z^{(k)}(x)$: logits of the model for the $k^{\\text{th}}$ augmentation\n",
        "- $T$: temperature parameter to sharpen the softmax (in my case, it's fixed at $0.5$)\n",
        "- $\\bar{p}_W(y = c \\mid x)$ is the marginal prediction after averaging softmax over augmentations with temperature scaling\n",
        "- $H(⋅)$ is the entropy of the marginal prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lurl9X1NoZtK",
      "metadata": {
        "id": "lurl9X1NoZtK"
      },
      "outputs": [],
      "source": [
        "def sharpened_softmax_entropy(logits, temperature=0.5):\n",
        "    \"\"\"\n",
        "    Compute the entropy of the marginal prediction using temperature-scaled softmax.\n",
        "    \"\"\"\n",
        "    # Apply temperature-scaled softmax to each augmentation\n",
        "    probabilities = F.softmax(logits / temperature, dim=1)\n",
        "\n",
        "    # Average across K augmentations to get marginal distribution\n",
        "    marginal_outputs = probabilities.mean(dim=0)\n",
        "\n",
        "    # Compute entropy of the marginal distribution with prevention of numerical error\n",
        "    marginal_entropy = -torch.sum(marginal_outputs * torch.log(marginal_outputs + 1e-8))\n",
        "\n",
        "    return marginal_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NnRGhfxORUOG",
      "metadata": {
        "id": "NnRGhfxORUOG"
      },
      "source": [
        "##### Marginal Entropy Loss with Weighted Augmentation\n",
        "\n",
        "The motication has came from the idea of not all augmentation is useful, so weighting the entropy contribtution from each augmentation Weighted marginal entropy loss where the weights are based on the model’s confidence (max softmax probability) for each augmentation.\n",
        "Takes logits for $K$ augmentations (shape $K×C$) where $C$ is number of classes, converts logits to probabilities with softmax. For each augmentation, takes the max probability (the model’s confidence). Normalizes these confidences so they sum to 1 — these become the weights. Computes a weighted average (marginal) of the probability distributions. Finally, calculates entropy of this weighted marginal distribution.\n",
        "\n",
        "$$\n",
        "\\quad w_k = \\frac{\\max_c p^{(k)}(y = c \\mid x)}{\\sum_{j=1}^{K} \\max_c p^{(j)}(y = c \\mid x)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\bar{p}_w(y = c \\mid x) = \\sum_{k=1}^{K} w_k \\cdot p^{(k)}(y = c \\mid x)\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "H(\\bar{p}_w(y \\mid x)) = - \\sum_{c=1}^{C} \\bar{p}_w(y = c \\mid x) \\log \\bar{p}_w(y = c \\mid x)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "*   $K$ is the number of augmentations\n",
        "*   $C$ is the number of classes\n",
        "*   $p^{(k)}(y = c \\mid x)$ is the softmax output for class $c$  on the $k^{\\text{th}}$ augmented input\n",
        "*   $w_k$  is the confidence weight of the $k^{\\text{th}}$ augmentation (based on max probability)\n",
        "*   $\\bar{p}_w(y = c \\mid x)$ is the weighted marginal probability distribution over classes\n",
        "* $H(⋅)$ is entropy of the marginal prediction\n",
        "\n",
        "\n",
        "\n",
        "This approach emphasizes augmentations where the model is more confident, weighting their contributions more heavily in the entropy calculation. This can help focus training or test-time adaptation on more reliable augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0D8zqNDPRRZd",
      "metadata": {
        "id": "0D8zqNDPRRZd"
      },
      "outputs": [],
      "source": [
        "def augmentation_weighted_entropy(logits):\n",
        "    \"\"\"\n",
        "    Computes augmentation-weighted marginal entropy loss.\n",
        "    \"\"\"\n",
        "    # Convert logits to probabilities\n",
        "    probabilities = F.softmax(logits, dim=1)\n",
        "\n",
        "    # Use max probability (confidence) as weight per augmentation\n",
        "    confidences, _ = probabilities.max(dim=1)\n",
        "\n",
        "    # Normalize weights to sum to 1\n",
        "    weights = confidences / confidences.sum()\n",
        "\n",
        "    # Weighted marginal distribution\n",
        "    marginal = torch.sum(probabilities * weights.unsqueeze(1), dim=0)\n",
        "\n",
        "    # Compute entropy of the marginal distribution with prevention of numerical error\n",
        "    entropy = -torch.sum(marginal * torch.log(marginal + 1e-8))\n",
        "\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29e1cbdd",
      "metadata": {
        "id": "29e1cbdd"
      },
      "source": [
        "#### Optimizer\n",
        "\n",
        "For optimizer, used AdamW with default $weight\\_decay=0.01$ as suggested by MEMO paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b70aa4",
      "metadata": {
        "id": "b9b70aa4"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, learning_rate):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), learning_rate)\n",
        "\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d6a76b1",
      "metadata": {
        "id": "3d6a76b1",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Dataset for the domain shift challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xgGISIwv73If",
      "metadata": {
        "id": "xgGISIwv73If"
      },
      "source": [
        "For the test dataset, following benchmarks are used:\n",
        "\n",
        "*   [ImageNet-Adversial](https://arxiv.org/abs/1907.07174) - set of images that contains natural adversarial examples and a classifier trained on ImageNet misclassifies or performs very poorly [ore info](https://arxiv.org/abs/1902.10811).\n",
        "*   [ImageNet-V2](https://github.com/modestyachts/ImageNetV2) - set of image that are recent re-collection of ImageNet with same categoriess, therefore contains distribution shift with respect to original dataset. [more info](https://github.com/hendrycks/natural-adv-examples)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lWRomNvAKgDX",
      "metadata": {
        "id": "lWRomNvAKgDX"
      },
      "source": [
        "#### Data label mapping\n",
        "\n",
        "Due to the difference of number of classes in ImageNet-A which contains only **200** out of 1000 classes in original dataset ImageNet, I needed to take into account this difference and handle with custom way. Following class names and indices are taken from [Natural Adversarial Examples Repository](https://github.com/hendrycks/natural-adv-examples/blob/master/eval.py) and [TPT repository](https://github.com/azshue/TPT/blob/main/data/imagenet_variants.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_3cAsl3BJYg4",
      "metadata": {
        "id": "_3cAsl3BJYg4"
      },
      "outputs": [],
      "source": [
        "imagenet_classes = [\"tench\", \"goldfish\", \"great white shark\", \"tiger shark\", \"hammerhead shark\", \"electric ray\", \"stingray\", \"rooster\", \"hen\", \"ostrich\", \"brambling\", \"goldfinch\", \"house finch\", \"junco\", \"indigo bunting\", \"American robin\", \"bulbul\", \"jay\", \"magpie\", \"chickadee\", \"American dipper\", \"kite (bird of prey)\", \"bald eagle\", \"vulture\", \"great grey owl\", \"fire salamander\", \"smooth newt\", \"newt\", \"spotted salamander\", \"axolotl\", \"American bullfrog\", \"tree frog\", \"tailed frog\", \"loggerhead sea turtle\", \"leatherback sea turtle\", \"mud turtle\", \"terrapin\", \"box turtle\", \"banded gecko\", \"green iguana\", \"Carolina anole\", \"desert grassland whiptail lizard\", \"agama\", \"frilled-necked lizard\", \"alligator lizard\", \"Gila monster\", \"European green lizard\", \"chameleon\", \"Komodo dragon\", \"Nile crocodile\", \"American alligator\", \"triceratops\", \"worm snake\", \"ring-necked snake\", \"eastern hog-nosed snake\", \"smooth green snake\", \"kingsnake\", \"garter snake\", \"water snake\", \"vine snake\", \"night snake\", \"boa constrictor\", \"African rock python\", \"Indian cobra\", \"green mamba\", \"sea snake\", \"Saharan horned viper\", \"eastern diamondback rattlesnake\", \"sidewinder rattlesnake\", \"trilobite\", \"harvestman\", \"scorpion\", \"yellow garden spider\", \"barn spider\", \"European garden spider\", \"southern black widow\", \"tarantula\", \"wolf spider\", \"tick\", \"centipede\", \"black grouse\", \"ptarmigan\", \"ruffed grouse\", \"prairie grouse\", \"peafowl\", \"quail\", \"partridge\", \"african grey parrot\", \"macaw\", \"sulphur-crested cockatoo\", \"lorikeet\", \"coucal\", \"bee eater\", \"hornbill\", \"hummingbird\", \"jacamar\", \"toucan\", \"duck\", \"red-breasted merganser\", \"goose\", \"black swan\", \"tusker\", \"echidna\", \"platypus\", \"wallaby\", \"koala\", \"wombat\", \"jellyfish\", \"sea anemone\", \"brain coral\", \"flatworm\", \"nematode\", \"conch\", \"snail\", \"slug\", \"sea slug\", \"chiton\", \"chambered nautilus\", \"Dungeness crab\", \"rock crab\", \"fiddler crab\", \"red king crab\", \"American lobster\", \"spiny lobster\", \"crayfish\", \"hermit crab\", \"isopod\", \"white stork\", \"black stork\", \"spoonbill\", \"flamingo\", \"little blue heron\", \"great egret\", \"bittern bird\", \"crane bird\", \"limpkin\", \"common gallinule\", \"American coot\", \"bustard\", \"ruddy turnstone\", \"dunlin\", \"common redshank\", \"dowitcher\", \"oystercatcher\", \"pelican\", \"king penguin\", \"albatross\", \"grey whale\", \"killer whale\", \"dugong\", \"sea lion\", \"Chihuahua\", \"Japanese Chin\", \"Maltese\", \"Pekingese\", \"Shih Tzu\", \"King Charles Spaniel\", \"Papillon\", \"toy terrier\", \"Rhodesian Ridgeback\", \"Afghan Hound\", \"Basset Hound\", \"Beagle\", \"Bloodhound\", \"Bluetick Coonhound\", \"Black and Tan Coonhound\", \"Treeing Walker Coonhound\", \"English foxhound\", \"Redbone Coonhound\", \"borzoi\", \"Irish Wolfhound\", \"Italian Greyhound\", \"Whippet\", \"Ibizan Hound\", \"Norwegian Elkhound\", \"Otterhound\", \"Saluki\", \"Scottish Deerhound\", \"Weimaraner\", \"Staffordshire Bull Terrier\", \"American Staffordshire Terrier\", \"Bedlington Terrier\", \"Border Terrier\", \"Kerry Blue Terrier\", \"Irish Terrier\", \"Norfolk Terrier\", \"Norwich Terrier\", \"Yorkshire Terrier\", \"Wire Fox Terrier\", \"Lakeland Terrier\", \"Sealyham Terrier\", \"Airedale Terrier\", \"Cairn Terrier\", \"Australian Terrier\", \"Dandie Dinmont Terrier\", \"Boston Terrier\", \"Miniature Schnauzer\", \"Giant Schnauzer\", \"Standard Schnauzer\", \"Scottish Terrier\", \"Tibetan Terrier\", \"Australian Silky Terrier\", \"Soft-coated Wheaten Terrier\", \"West Highland White Terrier\", \"Lhasa Apso\", \"Flat-Coated Retriever\", \"Curly-coated Retriever\", \"Golden Retriever\", \"Labrador Retriever\", \"Chesapeake Bay Retriever\", \"German Shorthaired Pointer\", \"Vizsla\", \"English Setter\", \"Irish Setter\", \"Gordon Setter\", \"Brittany dog\", \"Clumber Spaniel\", \"English Springer Spaniel\", \"Welsh Springer Spaniel\", \"Cocker Spaniel\", \"Sussex Spaniel\", \"Irish Water Spaniel\", \"Kuvasz\", \"Schipperke\", \"Groenendael dog\", \"Malinois\", \"Briard\", \"Australian Kelpie\", \"Komondor\", \"Old English Sheepdog\", \"Shetland Sheepdog\", \"collie\", \"Border Collie\", \"Bouvier des Flandres dog\", \"Rottweiler\", \"German Shepherd Dog\", \"Dobermann\", \"Miniature Pinscher\", \"Greater Swiss Mountain Dog\", \"Bernese Mountain Dog\", \"Appenzeller Sennenhund\", \"Entlebucher Sennenhund\", \"Boxer\", \"Bullmastiff\", \"Tibetan Mastiff\", \"French Bulldog\", \"Great Dane\", \"St. Bernard\", \"husky\", \"Alaskan Malamute\", \"Siberian Husky\", \"Dalmatian\", \"Affenpinscher\", \"Basenji\", \"pug\", \"Leonberger\", \"Newfoundland dog\", \"Great Pyrenees dog\", \"Samoyed\", \"Pomeranian\", \"Chow Chow\", \"Keeshond\", \"brussels griffon\", \"Pembroke Welsh Corgi\", \"Cardigan Welsh Corgi\", \"Toy Poodle\", \"Miniature Poodle\", \"Standard Poodle\", \"Mexican hairless dog (xoloitzcuintli)\", \"grey wolf\", \"Alaskan tundra wolf\", \"red wolf or maned wolf\", \"coyote\", \"dingo\", \"dhole\", \"African wild dog\", \"hyena\", \"red fox\", \"kit fox\", \"Arctic fox\", \"grey fox\", \"tabby cat\", \"tiger cat\", \"Persian cat\", \"Siamese cat\", \"Egyptian Mau\", \"cougar\", \"lynx\", \"leopard\", \"snow leopard\", \"jaguar\", \"lion\", \"tiger\", \"cheetah\", \"brown bear\", \"American black bear\", \"polar bear\", \"sloth bear\", \"mongoose\", \"meerkat\", \"tiger beetle\", \"ladybug\", \"ground beetle\", \"longhorn beetle\", \"leaf beetle\", \"dung beetle\", \"rhinoceros beetle\", \"weevil\", \"fly\", \"bee\", \"ant\", \"grasshopper\", \"cricket insect\", \"stick insect\", \"cockroach\", \"praying mantis\", \"cicada\", \"leafhopper\", \"lacewing\", \"dragonfly\", \"damselfly\", \"red admiral butterfly\", \"ringlet butterfly\", \"monarch butterfly\", \"small white butterfly\", \"sulphur butterfly\", \"gossamer-winged butterfly\", \"starfish\", \"sea urchin\", \"sea cucumber\", \"cottontail rabbit\", \"hare\", \"Angora rabbit\", \"hamster\", \"porcupine\", \"fox squirrel\", \"marmot\", \"beaver\", \"guinea pig\", \"common sorrel horse\", \"zebra\", \"pig\", \"wild boar\", \"warthog\", \"hippopotamus\", \"ox\", \"water buffalo\", \"bison\", \"ram (adult male sheep)\", \"bighorn sheep\", \"Alpine ibex\", \"hartebeest\", \"impala (antelope)\", \"gazelle\", \"arabian camel\", \"llama\", \"weasel\", \"mink\", \"European polecat\", \"black-footed ferret\", \"otter\", \"skunk\", \"badger\", \"armadillo\", \"three-toed sloth\", \"orangutan\", \"gorilla\", \"chimpanzee\", \"gibbon\", \"siamang\", \"guenon\", \"patas monkey\", \"baboon\", \"macaque\", \"langur\", \"black-and-white colobus\", \"proboscis monkey\", \"marmoset\", \"white-headed capuchin\", \"howler monkey\", \"titi monkey\", \"Geoffroy's spider monkey\", \"common squirrel monkey\", \"ring-tailed lemur\", \"indri\", \"Asian elephant\", \"African bush elephant\", \"red panda\", \"giant panda\", \"snoek fish\", \"eel\", \"silver salmon\", \"rock beauty fish\", \"clownfish\", \"sturgeon\", \"gar fish\", \"lionfish\", \"pufferfish\", \"abacus\", \"abaya\", \"academic gown\", \"accordion\", \"acoustic guitar\", \"aircraft carrier\", \"airliner\", \"airship\", \"altar\", \"ambulance\", \"amphibious vehicle\", \"analog clock\", \"apiary\", \"apron\", \"trash can\", \"assault rifle\", \"backpack\", \"bakery\", \"balance beam\", \"balloon\", \"ballpoint pen\", \"Band-Aid\", \"banjo\", \"baluster / handrail\", \"barbell\", \"barber chair\", \"barbershop\", \"barn\", \"barometer\", \"barrel\", \"wheelbarrow\", \"baseball\", \"basketball\", \"bassinet\", \"bassoon\", \"swimming cap\", \"bath towel\", \"bathtub\", \"station wagon\", \"lighthouse\", \"beaker\", \"military hat (bearskin or shako)\", \"beer bottle\", \"beer glass\", \"bell tower\", \"baby bib\", \"tandem bicycle\", \"bikini\", \"ring binder\", \"binoculars\", \"birdhouse\", \"boathouse\", \"bobsleigh\", \"bolo tie\", \"poke bonnet\", \"bookcase\", \"bookstore\", \"bottle cap\", \"hunting bow\", \"bow tie\", \"brass memorial plaque\", \"bra\", \"breakwater\", \"breastplate\", \"broom\", \"bucket\", \"buckle\", \"bulletproof vest\", \"high-speed train\", \"butcher shop\", \"taxicab\", \"cauldron\", \"candle\", \"cannon\", \"canoe\", \"can opener\", \"cardigan\", \"car mirror\", \"carousel\", \"tool kit\", \"cardboard box / carton\", \"car wheel\", \"automated teller machine\", \"cassette\", \"cassette player\", \"castle\", \"catamaran\", \"CD player\", \"cello\", \"mobile phone\", \"chain\", \"chain-link fence\", \"chain mail\", \"chainsaw\", \"storage chest\", \"chiffonier\", \"bell or wind chime\", \"china cabinet\", \"Christmas stocking\", \"church\", \"movie theater\", \"cleaver\", \"cliff dwelling\", \"cloak\", \"clogs\", \"cocktail shaker\", \"coffee mug\", \"coffeemaker\", \"spiral or coil\", \"combination lock\", \"computer keyboard\", \"candy store\", \"container ship\", \"convertible\", \"corkscrew\", \"cornet\", \"cowboy boot\", \"cowboy hat\", \"cradle\", \"construction crane\", \"crash helmet\", \"crate\", \"infant bed\", \"Crock Pot\", \"croquet ball\", \"crutch\", \"cuirass\", \"dam\", \"desk\", \"desktop computer\", \"rotary dial telephone\", \"diaper\", \"digital clock\", \"digital watch\", \"dining table\", \"dishcloth\", \"dishwasher\", \"disc brake\", \"dock\", \"dog sled\", \"dome\", \"doormat\", \"drilling rig\", \"drum\", \"drumstick\", \"dumbbell\", \"Dutch oven\", \"electric fan\", \"electric guitar\", \"electric locomotive\", \"entertainment center\", \"envelope\", \"espresso machine\", \"face powder\", \"feather boa\", \"filing cabinet\", \"fireboat\", \"fire truck\", \"fire screen\", \"flagpole\", \"flute\", \"folding chair\", \"football helmet\", \"forklift\", \"fountain\", \"fountain pen\", \"four-poster bed\", \"freight car\", \"French horn\", \"frying pan\", \"fur coat\", \"garbage truck\", \"gas mask or respirator\", \"gas pump\", \"goblet\", \"go-kart\", \"golf ball\", \"golf cart\", \"gondola\", \"gong\", \"gown\", \"grand piano\", \"greenhouse\", \"radiator grille\", \"grocery store\", \"guillotine\", \"hair clip\", \"hair spray\", \"half-track\", \"hammer\", \"hamper\", \"hair dryer\", \"hand-held computer\", \"handkerchief\", \"hard disk drive\", \"harmonica\", \"harp\", \"combine harvester\", \"hatchet\", \"holster\", \"home theater\", \"honeycomb\", \"hook\", \"hoop skirt\", \"gymnastic horizontal bar\", \"horse-drawn vehicle\", \"hourglass\", \"iPod\", \"clothes iron\", \"carved pumpkin\", \"jeans\", \"jeep\", \"T-shirt\", \"jigsaw puzzle\", \"rickshaw\", \"joystick\", \"kimono\", \"knee pad\", \"knot\", \"lab coat\", \"ladle\", \"lampshade\", \"laptop computer\", \"lawn mower\", \"lens cap\", \"letter opener\", \"library\", \"lifeboat\", \"lighter\", \"limousine\", \"ocean liner\", \"lipstick\", \"slip-on shoe\", \"lotion\", \"music speaker\", \"loupe magnifying glass\", \"sawmill\", \"magnetic compass\", \"messenger bag\", \"mailbox\", \"tights\", \"one-piece bathing suit\", \"manhole cover\", \"maraca\", \"marimba\", \"mask\", \"matchstick\", \"maypole\", \"maze\", \"measuring cup\", \"medicine cabinet\", \"megalith\", \"microphone\", \"microwave oven\", \"military uniform\", \"milk can\", \"minibus\", \"miniskirt\", \"minivan\", \"missile\", \"mitten\", \"mixing bowl\", \"mobile home\", \"ford model t\", \"modem\", \"monastery\", \"monitor\", \"moped\", \"mortar and pestle\", \"graduation cap\", \"mosque\", \"mosquito net\", \"vespa\", \"mountain bike\", \"tent\", \"computer mouse\", \"mousetrap\", \"moving van\", \"muzzle\", \"metal nail\", \"neck brace\", \"necklace\", \"baby pacifier\", \"notebook computer\", \"obelisk\", \"oboe\", \"ocarina\", \"odometer\", \"oil filter\", \"pipe organ\", \"oscilloscope\", \"overskirt\", \"bullock cart\", \"oxygen mask\", \"product packet / packaging\", \"paddle\", \"paddle wheel\", \"padlock\", \"paintbrush\", \"pajamas\", \"palace\", \"pan flute\", \"paper towel\", \"parachute\", \"parallel bars\", \"park bench\", \"parking meter\", \"railroad car\", \"patio\", \"payphone\", \"pedestal\", \"pencil case\", \"pencil sharpener\", \"perfume\", \"Petri dish\", \"photocopier\", \"plectrum\", \"Pickelhaube\", \"picket fence\", \"pickup truck\", \"pier\", \"piggy bank\", \"pill bottle\", \"pillow\", \"ping-pong ball\", \"pinwheel\", \"pirate ship\", \"drink pitcher\", \"block plane\", \"planetarium\", \"plastic bag\", \"plate rack\", \"farm plow\", \"plunger\", \"Polaroid camera\", \"pole\", \"police van\", \"poncho\", \"pool table\", \"soda bottle\", \"plant pot\", \"potter's wheel\", \"power drill\", \"prayer rug\", \"printer\", \"prison\", \"missile\", \"projector\", \"hockey puck\", \"punching bag\", \"purse\", \"quill\", \"quilt\", \"race car\", \"racket\", \"radiator\", \"radio\", \"radio telescope\", \"rain barrel\", \"recreational vehicle\", \"fishing casting reel\", \"reflex camera\", \"refrigerator\", \"remote control\", \"restaurant\", \"revolver\", \"rifle\", \"rocking chair\", \"rotisserie\", \"eraser\", \"rugby ball\", \"ruler measuring stick\", \"sneaker\", \"safe\", \"safety pin\", \"salt shaker\", \"sandal\", \"sarong\", \"saxophone\", \"scabbard\", \"weighing scale\", \"school bus\", \"schooner\", \"scoreboard\", \"CRT monitor\", \"screw\", \"screwdriver\", \"seat belt\", \"sewing machine\", \"shield\", \"shoe store\", \"shoji screen / room divider\", \"shopping basket\", \"shopping cart\", \"shovel\", \"shower cap\", \"shower curtain\", \"ski\", \"balaclava ski mask\", \"sleeping bag\", \"slide rule\", \"sliding door\", \"slot machine\", \"snorkel\", \"snowmobile\", \"snowplow\", \"soap dispenser\", \"soccer ball\", \"sock\", \"solar thermal collector\", \"sombrero\", \"soup bowl\", \"keyboard space bar\", \"space heater\", \"space shuttle\", \"spatula\", \"motorboat\", \"spider web\", \"spindle\", \"sports car\", \"spotlight\", \"stage\", \"steam locomotive\", \"through arch bridge\", \"steel drum\", \"stethoscope\", \"scarf\", \"stone wall\", \"stopwatch\", \"stove\", \"strainer\", \"tram\", \"stretcher\", \"couch\", \"stupa\", \"submarine\", \"suit\", \"sundial\", \"sunglasses\", \"sunglasses\", \"sunscreen\", \"suspension bridge\", \"mop\", \"sweatshirt\", \"swim trunks / shorts\", \"swing\", \"electrical switch\", \"syringe\", \"table lamp\", \"tank\", \"tape player\", \"teapot\", \"teddy bear\", \"television\", \"tennis ball\", \"thatched roof\", \"front curtain\", \"thimble\", \"threshing machine\", \"throne\", \"tile roof\", \"toaster\", \"tobacco shop\", \"toilet seat\", \"torch\", \"totem pole\", \"tow truck\", \"toy store\", \"tractor\", \"semi-trailer truck\", \"tray\", \"trench coat\", \"tricycle\", \"trimaran\", \"tripod\", \"triumphal arch\", \"trolleybus\", \"trombone\", \"hot tub\", \"turnstile\", \"typewriter keyboard\", \"umbrella\", \"unicycle\", \"upright piano\", \"vacuum cleaner\", \"vase\", \"vaulted or arched ceiling\", \"velvet fabric\", \"vending machine\", \"vestment\", \"viaduct\", \"violin\", \"volleyball\", \"waffle iron\", \"wall clock\", \"wallet\", \"wardrobe\", \"military aircraft\", \"sink\", \"washing machine\", \"water bottle\", \"water jug\", \"water tower\", \"whiskey jug\", \"whistle\", \"hair wig\", \"window screen\", \"window shade\", \"Windsor tie\", \"wine bottle\", \"airplane wing\", \"wok\", \"wooden spoon\", \"wool\", \"split-rail fence\", \"shipwreck\", \"sailboat\", \"yurt\", \"website\", \"comic book\", \"crossword\", \"traffic or street sign\", \"traffic light\", \"dust jacket\", \"menu\", \"plate\", \"guacamole\", \"consomme\", \"hot pot\", \"trifle\", \"ice cream\", \"popsicle\", \"baguette\", \"bagel\", \"pretzel\", \"cheeseburger\", \"hot dog\", \"mashed potatoes\", \"cabbage\", \"broccoli\", \"cauliflower\", \"zucchini\", \"spaghetti squash\", \"acorn squash\", \"butternut squash\", \"cucumber\", \"artichoke\", \"bell pepper\", \"cardoon\", \"mushroom\", \"Granny Smith apple\", \"strawberry\", \"orange\", \"lemon\", \"fig\", \"pineapple\", \"banana\", \"jackfruit\", \"cherimoya (custard apple)\", \"pomegranate\", \"hay\", \"carbonara\", \"chocolate syrup\", \"dough\", \"meatloaf\", \"pizza\", \"pot pie\", \"burrito\", \"red wine\", \"espresso\", \"tea cup\", \"eggnog\", \"mountain\", \"bubble\", \"cliff\", \"coral reef\", \"geyser\", \"lakeshore\", \"promontory\", \"sandbar\", \"beach\", \"valley\", \"volcano\", \"baseball player\", \"bridegroom\", \"scuba diver\", \"rapeseed\", \"daisy\", \"yellow lady's slipper\", \"corn\", \"acorn\", \"rose hip\", \"horse chestnut seed\", \"coral fungus\", \"agaric\", \"gyromitra\", \"stinkhorn mushroom\", \"earth star fungus\", \"hen of the woods mushroom\", \"bolete\", \"corn cob\", \"toilet paper\"]\n",
        "\n",
        "# ImageNet-A indexes to ImageNet\n",
        "# https://github.com/hendrycks/natural-adv-examples/blob/master/eval.py\n",
        "thousand_k_to_200 = {0: -1, 1: -1, 2: -1, 3: -1, 4: -1, 5: -1, 6: 0, 7: -1, 8: -1, 9: -1, 10: -1, 11: 1, 12: -1, 13: 2, 14: -1, 15: 3, 16: -1, 17: 4, 18: -1, 19: -1, 20: -1, 21: -1, 22: 5, 23: 6, 24: -1, 25: -1, 26: -1, 27: 7, 28: -1, 29: -1, 30: 8, 31: -1, 32: -1, 33: -1, 34: -1, 35: -1, 36: -1, 37: 9, 38: -1, 39: 10, 40: -1, 41: -1, 42: 11, 43: -1, 44: -1, 45: -1, 46: -1, 47: 12, 48: -1, 49: -1, 50: 13, 51: -1, 52: -1, 53: -1, 54: -1, 55: -1, 56: -1, 57: 14, 58: -1, 59: -1, 60: -1, 61: -1, 62: -1, 63: -1, 64: -1, 65: -1, 66: -1, 67: -1, 68: -1, 69: -1, 70: 15, 71: 16, 72: -1, 73: -1, 74: -1, 75: -1, 76: 17, 77: -1, 78: -1, 79: 18, 80: -1, 81: -1, 82: -1, 83: -1, 84: -1, 85: -1, 86: -1, 87: -1, 88: -1, 89: 19, 90: 20, 91: -1, 92: -1, 93: -1, 94: 21, 95: -1, 96: 22, 97: 23, 98: -1, 99: 24, 100: -1, 101: -1, 102: -1, 103: -1, 104: -1, 105: 25, 106: -1, 107: 26, 108: 27, 109: -1, 110: 28, 111: -1, 112: -1, 113: 29, 114: -1, 115: -1, 116: -1, 117: -1, 118: -1, 119: -1, 120: -1, 121: -1, 122: -1, 123: -1, 124: 30, 125: 31, 126: -1, 127: -1, 128: -1, 129: -1, 130: 32, 131: -1, 132: 33, 133: -1, 134: -1, 135: -1, 136: -1, 137: -1, 138: -1, 139: -1, 140: -1, 141: -1, 142: -1, 143: 34, 144: 35, 145: -1, 146: -1, 147: -1, 148: -1, 149: -1, 150: 36, 151: 37, 152: -1, 153: -1, 154: -1, 155: -1, 156: -1, 157: -1, 158: -1, 159: -1, 160: -1, 161: -1, 162: -1, 163: -1, 164: -1, 165: -1, 166: -1, 167: -1, 168: -1, 169: -1, 170: -1, 171: -1, 172: -1, 173: -1, 174: -1, 175: -1, 176: -1, 177: -1, 178: -1, 179: -1, 180: -1, 181: -1, 182: -1, 183: -1, 184: -1, 185: -1, 186: -1, 187: -1, 188: -1, 189: -1, 190: -1, 191: -1, 192: -1, 193: -1, 194: -1, 195: -1, 196: -1, 197: -1, 198: -1, 199: -1, 200: -1, 201: -1, 202: -1, 203: -1, 204: -1, 205: -1, 206: -1, 207: 38, 208: -1, 209: -1, 210: -1, 211: -1, 212: -1, 213: -1, 214: -1, 215: -1, 216: -1, 217: -1, 218: -1, 219: -1, 220: -1, 221: -1, 222: -1, 223: -1, 224: -1, 225: -1, 226: -1, 227: -1, 228: -1, 229: -1, 230: -1, 231: -1, 232: -1, 233: -1, 234: 39, 235: 40, 236: -1, 237: -1, 238: -1, 239: -1, 240: -1, 241: -1, 242: -1, 243: -1, 244: -1, 245: -1, 246: -1, 247: -1, 248: -1, 249: -1, 250: -1, 251: -1, 252: -1, 253: -1, 254: 41, 255: -1, 256: -1, 257: -1, 258: -1, 259: -1, 260: -1, 261: -1, 262: -1, 263: -1, 264: -1, 265: -1, 266: -1, 267: -1, 268: -1, 269: -1, 270: -1, 271: -1, 272: -1, 273: -1, 274: -1, 275: -1, 276: -1, 277: 42, 278: -1, 279: -1, 280: -1, 281: -1, 282: -1, 283: 43, 284: -1, 285: -1, 286: -1, 287: 44, 288: -1, 289: -1, 290: -1, 291: 45, 292: -1, 293: -1, 294: -1, 295: 46, 296: -1, 297: -1, 298: 47, 299: -1, 300: -1, 301: 48, 302: -1, 303: -1, 304: -1, 305: -1, 306: 49, 307: 50, 308: 51, 309: 52, 310: 53, 311: 54, 312: -1, 313: 55, 314: 56, 315: 57, 316: -1, 317: 58, 318: -1, 319: 59, 320: -1, 321: -1, 322: -1, 323: 60, 324: 61, 325: -1, 326: 62, 327: 63, 328: -1, 329: -1, 330: 64, 331: -1, 332: -1, 333: -1, 334: 65, 335: 66, 336: 67, 337: -1, 338: -1, 339: -1, 340: -1, 341: -1, 342: -1, 343: -1, 344: -1, 345: -1, 346: -1, 347: 68, 348: -1, 349: -1, 350: -1, 351: -1, 352: -1, 353: -1, 354: -1, 355: -1, 356: -1, 357: -1, 358: -1, 359: -1, 360: -1, 361: 69, 362: -1, 363: 70, 364: -1, 365: -1, 366: -1, 367: -1, 368: -1, 369: -1, 370: -1, 371: -1, 372: 71, 373: -1, 374: -1, 375: -1, 376: -1, 377: -1, 378: 72, 379: -1, 380: -1, 381: -1, 382: -1, 383: -1, 384: -1, 385: -1, 386: 73, 387: -1, 388: -1, 389: -1, 390: -1, 391: -1, 392: -1, 393: -1, 394: -1, 395: -1, 396: -1, 397: 74, 398: -1, 399: -1, 400: 75, 401: 76, 402: 77, 403: -1, 404: 78, 405: -1, 406: -1, 407: 79, 408: -1, 409: -1, 410: -1, 411: 80, 412: -1, 413: -1, 414: -1, 415: -1, 416: 81, 417: 82, 418: -1, 419: -1, 420: 83, 421: -1, 422: -1, 423: -1, 424: -1, 425: 84, 426: -1, 427: -1, 428: 85, 429: -1, 430: 86, 431: -1, 432: -1, 433: -1, 434: -1, 435: -1, 436: -1, 437: 87, 438: 88, 439: -1, 440: -1, 441: -1, 442: -1, 443: -1, 444: -1, 445: 89, 446: -1, 447: -1, 448: -1, 449: -1, 450: -1, 451: -1, 452: -1, 453: -1, 454: -1, 455: -1, 456: 90, 457: 91, 458: -1, 459: -1, 460: -1, 461: 92, 462: 93, 463: -1, 464: -1, 465: -1, 466: -1, 467: -1, 468: -1, 469: -1, 470: 94, 471: -1, 472: 95, 473: -1, 474: -1, 475: -1, 476: -1, 477: -1, 478: -1, 479: -1, 480: -1, 481: -1, 482: -1, 483: 96, 484: -1, 485: -1, 486: 97, 487: -1, 488: 98, 489: -1, 490: -1, 491: -1, 492: 99, 493: -1, 494: -1, 495: -1, 496: 100, 497: -1, 498: -1, 499: -1, 500: -1, 501: -1, 502: -1, 503: -1, 504: -1, 505: -1, 506: -1, 507: -1, 508: -1, 509: -1, 510: -1, 511: -1, 512: -1, 513: -1, 514: 101, 515: -1, 516: 102, 517: -1, 518: -1, 519: -1, 520: -1, 521: -1, 522: -1, 523: -1, 524: -1, 525: -1, 526: -1, 527: -1, 528: 103, 529: -1, 530: 104, 531: -1, 532: -1, 533: -1, 534: -1, 535: -1, 536: -1, 537: -1, 538: -1, 539: 105, 540: -1, 541: -1, 542: 106, 543: 107, 544: -1, 545: -1, 546: -1, 547: -1, 548: -1, 549: 108, 550: -1, 551: -1, 552: 109, 553: -1, 554: -1, 555: -1, 556: -1, 557: 110, 558: -1, 559: -1, 560: -1, 561: 111, 562: 112, 563: -1, 564: -1, 565: -1, 566: -1, 567: -1, 568: -1, 569: 113, 570: -1, 571: -1, 572: 114, 573: 115, 574: -1, 575: 116, 576: -1, 577: -1, 578: -1, 579: 117, 580: -1, 581: -1, 582: -1, 583: -1, 584: -1, 585: -1, 586: -1, 587: -1, 588: -1, 589: 118, 590: -1, 591: -1, 592: -1, 593: -1, 594: -1, 595: -1, 596: -1, 597: -1, 598: -1, 599: -1, 600: -1, 601: -1, 602: -1, 603: -1, 604: -1, 605: -1, 606: 119, 607: 120, 608: -1, 609: 121, 610: -1, 611: -1, 612: -1, 613: -1, 614: 122, 615: -1, 616: -1, 617: -1, 618: -1, 619: -1, 620: -1, 621: -1, 622: -1, 623: -1, 624: -1, 625: -1, 626: 123, 627: 124, 628: -1, 629: -1, 630: -1, 631: -1, 632: -1, 633: -1, 634: -1, 635: -1, 636: -1, 637: -1, 638: -1, 639: -1, 640: 125, 641: 126, 642: 127, 643: 128, 644: -1, 645: -1, 646: -1, 647: -1, 648: -1, 649: -1, 650: -1, 651: -1, 652: -1, 653: -1, 654: -1, 655: -1, 656: -1, 657: -1, 658: 129, 659: -1, 660: -1, 661: -1, 662: -1, 663: -1, 664: -1, 665: -1, 666: -1, 667: -1, 668: 130, 669: -1, 670: -1, 671: -1, 672: -1, 673: -1, 674: -1, 675: -1, 676: -1, 677: 131, 678: -1, 679: -1, 680: -1, 681: -1, 682: 132, 683: -1, 684: 133, 685: -1, 686: -1, 687: 134, 688: -1, 689: -1, 690: -1, 691: -1, 692: -1, 693: -1, 694: -1, 695: -1, 696: -1, 697: -1, 698: -1, 699: -1, 700: -1, 701: 135, 702: -1, 703: -1, 704: 136, 705: -1, 706: -1, 707: -1, 708: -1, 709: -1, 710: -1, 711: -1, 712: -1, 713: -1, 714: -1, 715: -1, 716: -1, 717: -1, 718: -1, 719: 137, 720: -1, 721: -1, 722: -1, 723: -1, 724: -1, 725: -1, 726: -1, 727: -1, 728: -1, 729: -1, 730: -1, 731: -1, 732: -1, 733: -1, 734: -1, 735: -1, 736: 138, 737: -1, 738: -1, 739: -1, 740: -1, 741: -1, 742: -1, 743: -1, 744: -1, 745: -1, 746: 139, 747: -1, 748: -1, 749: 140, 750: -1, 751: -1, 752: 141, 753: -1, 754: -1, 755: -1, 756: -1, 757: -1, 758: 142, 759: -1, 760: -1, 761: -1, 762: -1, 763: 143, 764: -1, 765: 144, 766: -1, 767: -1, 768: 145, 769: -1, 770: -1, 771: -1, 772: -1, 773: 146, 774: 147, 775: -1, 776: 148, 777: -1, 778: -1, 779: 149, 780: 150, 781: -1, 782: -1, 783: -1, 784: -1, 785: -1, 786: 151, 787: -1, 788: -1, 789: -1, 790: -1, 791: -1, 792: 152, 793: -1, 794: -1, 795: -1, 796: -1, 797: 153, 798: -1, 799: -1, 800: -1, 801: -1, 802: 154, 803: 155, 804: 156, 805: -1, 806: -1, 807: -1, 808: -1, 809: -1, 810: -1, 811: -1, 812: -1, 813: 157, 814: -1, 815: 158, 816: -1, 817: -1, 818: -1, 819: -1, 820: 159, 821: -1, 822: -1, 823: 160, 824: -1, 825: -1, 826: -1, 827: -1, 828: -1, 829: -1, 830: -1, 831: 161, 832: -1, 833: 162, 834: -1, 835: 163, 836: -1, 837: -1, 838: -1, 839: 164, 840: -1, 841: -1, 842: -1, 843: -1, 844: -1, 845: 165, 846: -1, 847: 166, 848: -1, 849: -1, 850: 167, 851: -1, 852: -1, 853: -1, 854: -1, 855: -1, 856: -1, 857: -1, 858: -1, 859: 168, 860: -1, 861: -1, 862: 169, 863: -1, 864: -1, 865: -1, 866: -1, 867: -1, 868: -1, 869: -1, 870: 170, 871: -1, 872: -1, 873: -1, 874: -1, 875: -1, 876: -1, 877: -1, 878: -1, 879: 171, 880: 172, 881: -1, 882: -1, 883: -1, 884: -1, 885: -1, 886: -1, 887: -1, 888: 173, 889: -1, 890: 174, 891: -1, 892: -1, 893: -1, 894: -1, 895: -1, 896: -1, 897: 175, 898: -1, 899: -1, 900: 176, 901: -1, 902: -1, 903: -1, 904: -1, 905: -1, 906: -1, 907: 177, 908: -1, 909: -1, 910: -1, 911: -1, 912: -1, 913: 178, 914: -1, 915: -1, 916: -1, 917: -1, 918: -1, 919: -1, 920: -1, 921: -1, 922: -1, 923: -1, 924: 179, 925: -1, 926: -1, 927: -1, 928: -1, 929: -1, 930: -1, 931: -1, 932: 180, 933: 181, 934: 182, 935: -1, 936: -1, 937: 183, 938: -1, 939: -1, 940: -1, 941: -1, 942: -1, 943: 184, 944: -1, 945: 185, 946: -1, 947: 186, 948: -1, 949: -1, 950: -1, 951: 187, 952: -1, 953: -1, 954: 188, 955: -1, 956: 189, 957: 190, 958: -1, 959: 191, 960: -1, 961: -1, 962: -1, 963: -1, 964: -1, 965: -1, 966: -1, 967: -1, 968: -1, 969: -1, 970: -1, 971: 192, 972: 193, 973: -1, 974: -1, 975: -1, 976: -1, 977: -1, 978: -1, 979: -1, 980: 194, 981: 195, 982: -1, 983: -1, 984: 196, 985: -1, 986: 197, 987: 198, 988: 199, 989: -1, 990: -1, 991: -1, 992: -1, 993: -1, 994: -1, 995: -1, 996: -1, 997: -1, 998: -1, 999: -1}\n",
        "indices_in_1k = [k for k in thousand_k_to_200 if thousand_k_to_200[k] != -1]\n",
        "\n",
        "# ImageNet-V2 indexes to ImageNet\n",
        "#https://github.com/azshue/TPT/blob/main/data/imagenet_variants.py\n",
        "imagenet_v_mask = [0, 1, 10, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 11,110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 12, 120, 121, 122,123, 124, 125, 126, 127, 128, 129, 13, 130, 131, 132, 133, 134, 135,136, 137, 138, 139, 14, 140, 141, 142, 143, 144, 145, 146, 147, 148,149, 15, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 16, 160,161, 162, 163, 164, 165, 166, 167, 168, 169, 17, 170, 171, 172, 173,174, 175, 176, 177, 178, 179, 18, 180, 181, 182, 183, 184, 185, 186,187, 188, 189, 19, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 2, 20, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 21, 210,211, 212, 213, 214, 215, 216, 217, 218, 219, 22, 220, 221, 222, 223,224, 225, 226, 227, 228, 229, 23, 230, 231, 232, 233, 234, 235, 236,237, 238, 239, 24, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 25, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 26, 260, 261,262, 263, 264, 265, 266, 267, 268, 269, 27, 270, 271, 272, 273, 274,275, 276, 277, 278, 279, 28, 280, 281, 282, 283, 284, 285, 286, 287,288, 289, 29, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 3, 30, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 31, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 32, 320, 321, 322, 323, 324,325, 326, 327, 328, 329, 33, 330, 331, 332, 333, 334, 335, 336, 337,338, 339, 34, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 35,350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 36, 360, 361, 362,363, 364, 365, 366, 367, 368, 369, 37, 370, 371, 372, 373, 374, 375,376, 377, 378, 379, 38, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 39, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 4, 40,400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 41, 410, 411, 412,413, 414, 415, 416, 417, 418, 419, 42, 420, 421, 422, 423, 424, 425,426, 427, 428, 429, 43, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 44, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 45, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 46, 460, 461, 462, 463,464, 465, 466, 467, 468, 469, 47, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 48, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 49, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 5, 50, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 51, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 52, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 53, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 54, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 55, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 56, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 57, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 58, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 59, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 6, 60, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 61, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 62, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 63, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 64, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 65, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 66, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 67, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 68, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 69, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 7, 70, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 71, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 72, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 73, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 74, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 75, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 76, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 77, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 78, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 79, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 8, 80, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 81, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 82, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 83, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 84, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 85, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 86, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 87, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 88, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 89, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 9, 90, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 91, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 92, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 93, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 94, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 95, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 96, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 97, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 98, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 99, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0i8-PSkGKl0q",
      "metadata": {
        "id": "0i8-PSkGKl0q"
      },
      "source": [
        "#### Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f894d01",
      "metadata": {
        "id": "2f894d01"
      },
      "outputs": [],
      "source": [
        "def get_data(im_groot, transform):\n",
        "    \"\"\"\n",
        "      Loads image dataset from the given root directory.\n",
        "\n",
        "      Args:\n",
        "          im_groot: path to root image dataset directory\n",
        "          transform: composition of transform functions to apply on each image\n",
        "      Returns:\n",
        "          A dataset object that can be used by DataLoader further purpose\n",
        "    \"\"\"\n",
        "    dataset = torchvision.datasets.ImageFolder(root=im_groot, transform=transform)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def pil_collate_fn(batch):\n",
        "    \"\"\"\n",
        "      Custom function for DataLoader, which keeps PIL image, labels pairs in batch,\n",
        "      for in order to apply my transformation during the TTA, rather than in\n",
        "      data pre-processing\n",
        "\n",
        "      Args:\n",
        "          batch (list of tuples): Each element is a tuple (PIL image, label).\n",
        "      Returns:\n",
        "          list of images, tensor of labels\n",
        "    \"\"\"\n",
        "    images, labels = zip(*batch)\n",
        "\n",
        "    return list(images), torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11f1d66f",
      "metadata": {
        "id": "11f1d66f",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Preparation for experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b318583",
      "metadata": {
        "id": "2b318583",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Pre-trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90c114e-479c-4481-80da-f93a7d3bc88b",
      "metadata": {
        "id": "d90c114e-479c-4481-80da-f93a7d3bc88b"
      },
      "source": [
        "For pre-trained model I used two different following models as backbone to the implementation:\n",
        "\n",
        "1.   First,  I used [**ResNet-50**](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html) which is trained on ImageNet as this model is trained on original ImageNet datasset which consists of 1000 classes of images. The model was introduced in [He. et. al](https://arxiv.org/abs/1512.03385), is a CNN that has residual connections ($y=f(x, θ) + x$, where $x$ is original input and $f(x, θ)$ is output of the convolution layer), which helps training deeper models with gradient flow without vanishing. The model consists of 50 layers, processes the input image through a the convolutional layers with residual connections, progressively extracting high-level features, then applies global average pooling and a fully connected layer to predict the class label. The architecture is following:\n",
        "\n",
        "  *   1 convolution layer (7x7),\n",
        "  *   1 maxpool layer (7x7),\n",
        "  *   16 Residual blocks, consisting of:\n",
        "      *   Conv layer (1x1)\n",
        "      *   Conv layer (3x3)\n",
        "      *   Conv layer (1x1)\n",
        "      *   Identity Bypass\n",
        "      *   ReLU output\n",
        "  *   Global avg-pooling layer\n",
        "  *   FC layer\n",
        "  *   Softmax output layer\n",
        "\n",
        "Resnet50 model has BatchNorm layer, therefore, I also added adaptive batch norm when using Resnet50 as backbone. The weight difference source can be found [here](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights)\n",
        "  \n",
        "2.   For second, as the MEMO paper used vision transformer model in their experiment, I used [**Vit-B/16**](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html), the base Vision Transformer model that used Transformer architechture for image classification task. Splits an input image intopatches, embeds them into vectors, adds a special [CLS] token and positional encodings, processes the sequence through a 12 Transformer encoder, and uses the final [CLS] token's representation to predict the class label via a linear classifier. The [CLS] token accumulates information from all the patches by the attention. The final classifier learns to use that token’s representation to output a prediction. The architecture steps of the model is following:\n",
        "  *   Split into patches (16×16 ~ vit-b/16)\n",
        "  *   Linear embedding\n",
        "  *   Add CLS token\n",
        "  *   Positional Embedding\n",
        "  *   12 Transformer blocks, consisting of:\n",
        "      * LayerNorm\n",
        "      * Multi head Self-Attention\n",
        "      * LayerNorm\n",
        "      * MLP\n",
        "      * Residual connection\n",
        "  *   CLS Token Output\n",
        "  *   Classification Head (Linear layer)\n",
        "  *   Softmax output\n",
        "\n",
        "The Vit-B/16 model has only layer norm is implemented, therefore when using Vit-B/16 as a backbone, adaptive batch norm is not applied at all.\n",
        "\n",
        "***Instruction***: For each pre-trained model, I defined cells for preparing the model, data loader, learning rate, optimizer and different choice of augmentations. Therefore, to run an experiment, only need to run cell for desired pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N6yp58kC8ywG",
      "metadata": {
        "id": "N6yp58kC8ywG",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d11c928",
      "metadata": {
        "id": "1d11c928"
      },
      "outputs": [],
      "source": [
        "# Pre-trained model ResNet50\n",
        "def get_resnet(is_default_weight=True):\n",
        "    \"\"\"\n",
        "      The function returns ResNet50 pre-trained model, depending on the weight version specification\n",
        "\n",
        "      Arg:\n",
        "          is_default_weight: specifies weights version of the model that need to take\n",
        "              true: model with weights `IMAGENET1K_V2` with higher top-1 accuracy 80.85\n",
        "              false: model with weights `IMAGENET1K_V1` with top-1 accuracy 76.13\n",
        "    \"\"\"\n",
        "    if is_default_weight:\n",
        "        preprocess = ResNet50_Weights.DEFAULT.transforms()\n",
        "        return preprocess, resnet50(weights=ResNet50_Weights.DEFAULT)#.to(device)\n",
        "    else:\n",
        "        preprocess = ResNet50_Weights.IMAGENET1K_V1.transforms()\n",
        "        return preprocess, resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)#.to(device)\n",
        "\n",
        "def get_resnet_loader(is_default_weight=True, augmentation_option=\"option1\", is_imgnet_a=True):\n",
        "    preprocess, ResNet = get_resnet(is_default_weight)\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.00025\n",
        "\n",
        "    # optimizer\n",
        "    optimizer_resnet = get_optimizer(ResNet, learning_rate)\n",
        "\n",
        "    match augmentation_option:\n",
        "        case 'option1':\n",
        "            # For baseline\n",
        "            # Preprocess first, and then put augmentation RandomResizedCrop\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a =  get_data(im_groot_imagenet_a, preprocess)\n",
        "                data_loader_imagenet_a = torch.utils.data.DataLoader(dataset_imagenet_a, DEFAULT_BATCH_SIZE)\n",
        "            else:\n",
        "                dataset_imagenet_v2 =  get_data(im_groot_imagenet_v2, preprocess)\n",
        "                data_loader_imagenet_v2 = torch.utils.data.DataLoader(dataset_imagenet_v2, DEFAULT_BATCH_SIZE)\n",
        "\n",
        "            # augmentations = None\n",
        "            augmentations = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.Resize(preprocess.resize_size, interpolation=preprocess.interpolation,\n",
        "                            antialias=preprocess.antialias),\n",
        "                v2.CenterCrop(preprocess.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess.mean, preprocess.std)\n",
        "            ])\n",
        "\n",
        "        case 'option2':\n",
        "            # For testing MEMO\n",
        "            # Augmentation - RandomResizedCrop\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a =  get_data(im_groot_imagenet_a, None)\n",
        "                data_loader_imagenet_a = torch.utils.data.DataLoader(dataset_imagenet_a, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "            else:\n",
        "                dataset_imagenet_v2 =  get_data(im_groot_imagenet_v2, None)\n",
        "                data_loader_imagenet_v2 = torch.utils.data.DataLoader(dataset_imagenet_v2, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "\n",
        "            augmentations = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.RandomResizedCrop(224, antialias=True),\n",
        "                v2.Resize(preprocess.resize_size, interpolation=preprocess.interpolation,\n",
        "                            antialias=preprocess.antialias),\n",
        "                v2.CenterCrop(preprocess.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess.mean, preprocess.std)\n",
        "            ])\n",
        "        case 'option3':\n",
        "            # For testing MEMO\n",
        "            # Augmentation - RandomResizedCrop + RandomPerspective\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a =  get_data(im_groot_imagenet_a, None)\n",
        "                data_loader_imagenet_a = torch.utils.data.DataLoader(dataset_imagenet_a, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "            else:\n",
        "                dataset_imagenet_v2 =  get_data(im_groot_imagenet_v2, None)\n",
        "                data_loader_imagenet_v2 = torch.utils.data.DataLoader(dataset_imagenet_v2, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "\n",
        "            augmentations = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.RandomResizedCrop(224, antialias=True),\n",
        "                v2.RandomHorizontalFlip(),\n",
        "                v2.Resize(preprocess.resize_size, interpolation=preprocess.interpolation,\n",
        "                            antialias=preprocess.antialias),\n",
        "                v2.CenterCrop(preprocess.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess.mean, preprocess.std)\n",
        "            ])\n",
        "        case 'option4':\n",
        "            # For testing MEMO\n",
        "            # Augmentation - RandomResizedCrop + RandomPerspective + RandomAffine + RandomHorizontalFlip\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a =  get_data(im_groot_imagenet_a, None)\n",
        "                data_loader_imagenet_a = torch.utils.data.DataLoader(dataset_imagenet_a, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "            else:\n",
        "                dataset_imagenet_v2 =  get_data(im_groot_imagenet_v2, None)\n",
        "                data_loader_imagenet_v2 = torch.utils.data.DataLoader(dataset_imagenet_v2, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "\n",
        "            augmentations = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.RandomResizedCrop(224, antialias=True),\n",
        "                v2.RandomAffine(degrees=0, scale=(0.9, 1.2)),\n",
        "                v2.RandomPerspective(),\n",
        "                v2.RandomHorizontalFlip(),\n",
        "                v2.Resize(preprocess.resize_size, interpolation=preprocess.interpolation,\n",
        "                            antialias=preprocess.antialias),\n",
        "                v2.CenterCrop(preprocess.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess.mean, preprocess.std)\n",
        "            ])\n",
        "\n",
        "    if is_imgnet_a == True:\n",
        "        return ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess\n",
        "\n",
        "    return ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bkNSGkLs84b8",
      "metadata": {
        "id": "bkNSGkLs84b8",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### VIT-B/16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jMAmMpcH89Wp",
      "metadata": {
        "id": "jMAmMpcH89Wp"
      },
      "outputs": [],
      "source": [
        "# Pre-trained model VIT-B/16\n",
        "def get_vit():\n",
        "    \"\"\"\n",
        "      The function returns VIT-B/16 pre-trained model, depending on the weight version specification\n",
        "                           the model with weights `IMAGENET1K_V1` with higher top-1 accuracy 81.07\n",
        "    \"\"\"\n",
        "    preprocess_vit = ViT_B_16_Weights.DEFAULT.transforms()\n",
        "    return preprocess_vit, vit_b_16(weights=ViT_B_16_Weights.DEFAULT)#.to(device)\n",
        "\n",
        "def get_vit_loader(augmentation_option, is_imgnet_a):\n",
        "    preprocess_vit, VIT_V1 = get_vit()\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.00005\n",
        "\n",
        "    # optimizer\n",
        "    optimizer_vit = get_optimizer(VIT_V1, learning_rate)\n",
        "\n",
        "    match augmentation_option:\n",
        "        case 'option1':\n",
        "            # For baseline testing\n",
        "            # Preprocess first, and then put augmentation RandomResizedCrop\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a_vit =  get_data(im_groot_imagenet_a, preprocess_vit)\n",
        "                data_loader_imagenet_a_vit = torch.utils.data.DataLoader(dataset_imagenet_a_vit, DEFAULT_BATCH_SIZE)\n",
        "            else:\n",
        "                dataset_imagenet_v2_vit =  get_data(im_groot_imagenet_v2, preprocess_vit)\n",
        "                data_loader_imagenet_v2_vit = torch.utils.data.DataLoader(dataset_imagenet_v2_vit, DEFAULT_BATCH_SIZE)\n",
        "\n",
        "            # augmentations_vit = None\n",
        "            augmentations_vit = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.Resize(preprocess_vit.resize_size, interpolation=preprocess_vit.interpolation,\n",
        "                            antialias=preprocess_vit.antialias),\n",
        "                v2.CenterCrop(preprocess_vit.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess_vit.mean, preprocess_vit.std)\n",
        "            ])\n",
        "\n",
        "        case 'option2':\n",
        "            # For testing MEMO\n",
        "            # Augmentation - RandomResizedCrop\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a_vit =  get_data(im_groot_imagenet_a, transform=None)\n",
        "                data_loader_imagenet_a_vit = torch.utils.data.DataLoader(dataset_imagenet_a_vit, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "            else:\n",
        "                dataset_imagenet_v2_vit =  get_data(im_groot_imagenet_v2, transform=None)\n",
        "                data_loader_imagenet_v2_vit = torch.utils.data.DataLoader(dataset_imagenet_v2_vit, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "\n",
        "            augmentations_vit = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.RandomResizedCrop(224, antialias=True),\n",
        "                v2.Resize(preprocess_vit.resize_size, interpolation=preprocess_vit.interpolation,\n",
        "                          antialias=preprocess_vit.antialias),\n",
        "                v2.CenterCrop(preprocess_vit.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess_vit.mean, preprocess_vit.std)\n",
        "            ])\n",
        "        case 'option3':\n",
        "            # For testing MEMO\n",
        "            # Augmentation - RandomResizedCrop + RandomPerspective\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a_vit =  get_data(im_groot_imagenet_a, transform=None)\n",
        "                data_loader_imagenet_a_vit = torch.utils.data.DataLoader(dataset_imagenet_a_vit, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "            else:\n",
        "                dataset_imagenet_v2_vit =  get_data(im_groot_imagenet_v2, transform=None)\n",
        "                data_loader_imagenet_v2_vit = torch.utils.data.DataLoader(dataset_imagenet_v2_vit, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "\n",
        "            augmentations_vit = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.RandomResizedCrop(224, antialias=True),\n",
        "                v2.RandomHorizontalFlip(),\n",
        "                v2.Resize(preprocess_vit.resize_size, interpolation=preprocess_vit.interpolation,\n",
        "                          antialias=preprocess_vit.antialias),\n",
        "                v2.CenterCrop(preprocess_vit.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess_vit.mean, preprocess_vit.std)\n",
        "            ])\n",
        "        case 'option4':\n",
        "            # For testing MEMO\n",
        "            # Augmentation - RandomResizedCrop + RandomPerspective + RandomAffine + RandomHorizontalFlip\n",
        "            if is_imgnet_a == True:\n",
        "                dataset_imagenet_a_vit =  get_data(im_groot_imagenet_a, transform=None)\n",
        "                data_loader_imagenet_a_vit = torch.utils.data.DataLoader(dataset_imagenet_a_vit, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "            else:\n",
        "                dataset_imagenet_v2_vit =  get_data(im_groot_imagenet_v2, transform=None)\n",
        "                data_loader_imagenet_v2_vit = torch.utils.data.DataLoader(dataset_imagenet_v2_vit, DEFAULT_BATCH_SIZE, collate_fn=pil_collate_fn)\n",
        "\n",
        "            augmentations_vit = T.Compose([\n",
        "                v2.ToImage(),\n",
        "                v2.ToDtype(torch.uint8, scale=True),\n",
        "                v2.RandomResizedCrop(224, antialias=True),\n",
        "                v2.RandomAffine(degrees=0, scale=(0.9, 1.2)),\n",
        "                v2.RandomPerspective(),\n",
        "                v2.RandomHorizontalFlip(),\n",
        "                v2.Resize(preprocess_vit.resize_size, interpolation=preprocess_vit.interpolation,\n",
        "                          antialias=preprocess_vit.antialias),\n",
        "                v2.CenterCrop(preprocess_vit.crop_size),\n",
        "                v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(preprocess_vit.mean, preprocess_vit.std)\n",
        "            ])\n",
        "\n",
        "    if is_imgnet_a == True:\n",
        "        return VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, augmentations_vit, preprocess_vit\n",
        "\n",
        "    return VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, augmentations_vit, preprocess_vit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iGcKXIxC6pRS",
      "metadata": {
        "id": "iGcKXIxC6pRS",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iaI-73yh98Dz",
      "metadata": {
        "id": "iaI-73yh98Dz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Evaluates the performance of a trained model on a given test dataset\n",
        "  for testing baseline without applying the TTA method\n",
        "\n",
        "  Args:\n",
        "      model:         The model to be evaluated.\n",
        "      data_loader:   DataLoader for the test dataset.\n",
        "      device:        Device to perform computation on\n",
        "  Returns:\n",
        "      The test accuracy computed over the dataset.\n",
        "\"\"\"\n",
        "def test_model(model, data_loader, device=device):\n",
        "    # for computing accuracy\n",
        "    count = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Load model into device (GPU)\n",
        "    model.to(device)\n",
        "\n",
        "    # Set the network to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation (it's only a test time, model update should not happen)\n",
        "    with torch.no_grad():\n",
        "        for _, (input, target) in enumerate(tqdm(data_loader)):\n",
        "            # Load data into device (GPU)\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(input)\n",
        "\n",
        "            # Get the predicted class by taking the index of the max logit across classes\n",
        "            _, predicted = output.max(1)\n",
        "\n",
        "            # Increase total sample count by batch size (which is 1)\n",
        "            count += input.shape[0]\n",
        "\n",
        "            # Compare prediction with ground truth and count correct predictions\n",
        "            accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "            del output, input, target, predicted\n",
        "\n",
        "    # Compute final accuracy\n",
        "    return accuracy / count * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lwxrNl4w-jt3",
      "metadata": {
        "id": "lwxrNl4w-jt3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Evaluates the performance of a model that applies TTA method\n",
        "\n",
        "  Args:\n",
        "      model:         The model to be evaluated.\n",
        "      data_loader:   DataLoader for the test dataset.\n",
        "      device:        Device to perform computation on\n",
        "  Returns:\n",
        "      The test accuracy computed over the dataset.\n",
        "  \"\"\"\n",
        "def test_model_tta_applied(model, data_loader, device=device):\n",
        "    # for computing accuracy\n",
        "    count = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Load model into device (GPU)\n",
        "    model.to(device)\n",
        "\n",
        "    # Set the network to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for _, (input, target) in enumerate(tqdm(data_loader)):\n",
        "        # Load data into device (GPU)\n",
        "        input = input[0]\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Forward pass - only one example at a time\n",
        "        output = model([input])\n",
        "\n",
        "        # Get the predicted class by taking the index of the max logit across classes\n",
        "        _, predicted = output.max(1)\n",
        "\n",
        "          # Increase total sample count by batch size (which is 1)\n",
        "        count += 1\n",
        "\n",
        "        # Compare prediction with ground truth and count correct predictions\n",
        "        accuracy += predicted.eq(target).sum().item()\n",
        "        del output, input, target, predicted\n",
        "\n",
        "    # Compute final accuracy\n",
        "    return accuracy / count * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kgrnzhTPSDsH",
      "metadata": {
        "id": "kgrnzhTPSDsH"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee10c95-361a-4be3-b03a-cf08a7eeeb30",
      "metadata": {
        "id": "1ee10c95-361a-4be3-b03a-cf08a7eeeb30",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### Logger util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wJVpKcGxpxmK",
      "metadata": {
        "id": "wJVpKcGxpxmK"
      },
      "outputs": [],
      "source": [
        "def setup_experiment_logger(log_folder: str, experiment_name: str) -> logging.Logger:\n",
        "    \"\"\"\n",
        "        For the purpose of loggin my result\n",
        "        As there is a risk of cannot see my result if aws account signed out or something happens\n",
        "    \"\"\"\n",
        "    os.makedirs(log_folder, exist_ok=True)\n",
        "\n",
        "    log_path = os.path.join(log_folder, f\"{experiment_name}.log\")\n",
        "\n",
        "    logger = logging.getLogger(experiment_name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    if not logger.handlers:\n",
        "        file_handler = logging.FileHandler(log_path)\n",
        "        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MYM8eZOT6Jw4",
      "metadata": {
        "id": "MYM8eZOT6Jw4",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14b2c722",
      "metadata": {
        "id": "14b2c722",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Baseline ~ ResNet50_V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d531524-cdcf-4330-8af6-8b1532e5557d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "11332b6f8743415aabf5d33db21df463"
          ]
        },
        "id": "9d531524-cdcf-4330-8af6-8b1532e5557d",
        "outputId": "b00ae486-ab10-4b1b-c347-6a6c2376dddd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11332b6f8743415aabf5d33db21df463",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: Baseline - ResNet50_V1 ~ ImageNet-A\n",
            "0.02666666666666667\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, _, _ = get_resnet_loader(is_default_weight=False, augmentation_option=\"option1\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet, learning_rate, optimizer_resnet, marginal_entropy_loss, indices_in_1k, apply_tta=False, augmentations=None)\n",
        "test_result = test_model(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: Baseline - ResNet50_V1 ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"Baseline_ResNet50_V1_ImageNet-A\")\n",
        "logger.info(\"Result: Baseline - ResNet50_V1 ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b104dff4-4dab-4f74-99f2-0cfea8934714",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3e2cdaa42fc84ce59b655cf64849c1e5"
          ]
        },
        "id": "b104dff4-4dab-4f74-99f2-0cfea8934714",
        "outputId": "2b110e97-3b29-4072-8c06-0cd4191a27cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e2cdaa42fc84ce59b655cf64849c1e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: Baseline - ResNet50_V1 ~ ImageNet-V2\n",
            "63.14999999999999\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, _, _ = get_resnet_loader(is_default_weight=False, augmentation_option=\"option1\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet, learning_rate, optimizer_resnet, marginal_entropy_loss, imagenet_v_mask, apply_tta=False, augmentations=None)\n",
        "test_result = test_model(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: Baseline - ResNet50_V1 ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"Baseline_ResNet50_V1_ImageNet-V2\")\n",
        "logger.info(\"Result: Baseline - ResNet50_V1 ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390fe426-5d07-49c5-b8e0-d255fd5489d6",
      "metadata": {
        "id": "390fe426-5d07-49c5-b8e0-d255fd5489d6",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Baseline ~ ResNet50_V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fRjD9z7I3gQt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "52faa556b795487f9e1920b0c9fb61cd",
            "47f2df8481c2421fb6b994a79d5dbb22",
            "7ae0d14232324444a4779276e5393c44",
            "77632b65724b42fb8e57b04bf73253bf",
            "8ea1e6d147e34ea8b3344199a913674d",
            "c7989acae16d453ba40ca5d350207779",
            "52dca400e0dd4182ac6ae333b98881d4",
            "4cf96421b88c43748ad95bf6686829b7",
            "399bedc9fd7c4a58b08dd0b2270ca7bb",
            "4edda447619f4dc58392a6bc019418fe",
            "c699a95d7c0d464692a347a8e89ccd67",
            "b4271c4030364a159322e9874fa578bc"
          ]
        },
        "id": "fRjD9z7I3gQt",
        "outputId": "86a3e0c5-ecbb-4d9d-cac6-2aefa867601d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4271c4030364a159322e9874fa578bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: Baseline - ResNet50_V2 ~ ImageNet-A\n",
            "14.266666666666666\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, _, _ = get_resnet_loader(is_default_weight=True, augmentation_option=\"option1\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet, learning_rate, optimizer_resnet, marginal_entropy_loss, indices_in_1k, apply_tta=False, augmentations=None)\n",
        "test_result = test_model(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: Baseline - ResNet50_V2 ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"Baseline_ResNet50_V2_ImageNet-A\")\n",
        "logger.info(\"Result: Baseline - ResNet50_V2 ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cQ3S0ACa3hS3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ccabe627cfe3420cb729280661d28c65"
          ]
        },
        "id": "cQ3S0ACa3hS3",
        "outputId": "8a442857-226c-4fa2-852d-43bd0b969587"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccabe627cfe3420cb729280661d28c65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: Baseline - ResNet50_V2 ~ ImageNet-V2\n",
            "69.89\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, _, _ = get_resnet_loader(is_default_weight=True, augmentation_option=\"option1\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet, learning_rate, optimizer_resnet, marginal_entropy_loss, imagenet_v_mask, apply_tta=False, augmentations=None)\n",
        "test_result = test_model(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: Baseline - ResNet50_V2 ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"Baseline_ResNet50_V2_ImageNet-V2\")\n",
        "logger.info(\"Result: Baseline - ResNet50_V2 ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1SrIp2sxEvhU",
      "metadata": {
        "id": "1SrIp2sxEvhU",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Baseline ~ VIT-B/16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PIJRGHoH3kOV",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9e17164c104542a19e22f03743045d48"
          ]
        },
        "id": "PIJRGHoH3kOV",
        "outputId": "e7538e7b-33db-48e2-ba80-f59f2629978e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e17164c104542a19e22f03743045d48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: Baseline - ViT_B_16_V1 ~ ImageNet-A\n",
            "20.746666666666666\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, _, _ = get_vit_loader(augmentation_option=\"option1\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(VIT_V1, learning_rate, optimizer_vit, marginal_entropy_loss, indices_in_1k, apply_tta=False, augmentations=None)\n",
        "test_result = test_model(model, data_loader_imagenet_a_vit)\n",
        "\n",
        "print(\"\\nResult: Baseline - ViT_B_16_V1 ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"Baseline_ViT_B_16_V1_ImageNet-A\")\n",
        "logger.info(\"Result: Baseline - ViT_B_16_V1 ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w_mWCC3O3l74",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c565c15c7409453791677235dc8312a0"
          ]
        },
        "id": "w_mWCC3O3l74",
        "outputId": "12760bb7-27ad-40e3-bfd6-7a7e9a0e43af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c565c15c7409453791677235dc8312a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: Baseline - ViT_B_16_V1 ~ ImageNet-V2\n",
            "69.57\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, _, _ = get_vit_loader(augmentation_option=\"option1\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(VIT_V1, learning_rate, optimizer_vit, marginal_entropy_loss, imagenet_v_mask, apply_tta=False, augmentations=None)\n",
        "test_result = test_model(model, data_loader_imagenet_v2_vit)\n",
        "\n",
        "print(\"\\nResult: Baseline - ViT_B_16_V1 ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"Baseline_ViT_B_16_V1_ImageNet-V2\")\n",
        "logger.info(\"Result: Baseline - ViT_B_16_V1 ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SWLjUocF6M7b",
      "metadata": {
        "id": "SWLjUocF6M7b"
      },
      "source": [
        "### Test Time Adaptation applied"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KHy89o9ikAKT",
      "metadata": {
        "id": "KHy89o9ikAKT",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V2 + MEMO ~ applied TTA ~ RandomResizedCrop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6XHpZ9e3kH6q",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6e9b021f309a4247863a448a9637f149"
          ]
        },
        "id": "6XHpZ9e3kH6q",
        "outputId": "f2953ed9-3afe-44b2-fe19-f48cd923c547"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e9b021f309a4247863a448a9637f149",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-A\n",
            "18.413333333333334\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + RandomResizedCrop ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_RandomResizedCrop_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + RandomResizedCrop ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TIjlZcb2o3Xb",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "87b0b34b84f54312b46eb445a1746981"
          ]
        },
        "id": "TIjlZcb2o3Xb",
        "outputId": "df7d53a5-fee1-42f7-b559-2a5f67077645"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87b0b34b84f54312b46eb445a1746981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-V2\n",
            "76.03\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_RandomResizedCrop_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + RandomResizedCrop ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aGnmNP_3f_r0",
      "metadata": {
        "id": "aGnmNP_3f_r0",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V2 + MEMO ~ applied TTA ~ RandomResizedCrop + BN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64X2Im0SgBEP",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c7c8288fb16c4d0b89910943ab788382"
          ]
        },
        "id": "64X2Im0SgBEP",
        "outputId": "e51792c2-1cb1-4e8c-c231-17c8170a2a4e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7c8288fb16c4d0b89910943ab788382",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-A\n",
            "24.240000000000002\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RandomResizedCrop_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sPNrHRAXgP3Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f0c2d70b6a994b2e8ec5e7bef7f8dbfd",
            "7f068021cc4342fa8136bc02f9b728c5",
            "5d985f88754947cf8f660e39102e1d6b",
            "d1f068baf60f4a0bbbc27a57e63bbfc9",
            "928446f9025e41ad8d5557bf10eb77d1",
            "365e21074905465584ec1dc7568bd8c1",
            "a4a918f7fd7343bf8364c7136a91ffb0",
            "e23ab46c7bee44e7bd5d0ce72aad5d9e",
            "90dee414cd0640baad015dcfd4b84d52",
            "57a9725dd4384351bbc4884919b5ae2f",
            "285429ef03b248dba822822334166da4",
            "4b22c09408cf4349a73c62664448a7b5"
          ]
        },
        "id": "sPNrHRAXgP3Y",
        "outputId": "fcd35238-ffdd-48a9-ed04-d544b133eb39"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b22c09408cf4349a73c62664448a7b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-V2\n",
            "78.69\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RandomResizedCrop_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oNAfvY1y-0-R",
      "metadata": {
        "id": "oNAfvY1y-0-R",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V2 + MEMO ~ applied TTA + BN + Multi Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d064c2a7-33ac-4df9-a820-91ed11854a3e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "54b9a9cffc3844789369754d0ce75101"
          ]
        },
        "id": "d064c2a7-33ac-4df9-a820-91ed11854a3e",
        "outputId": "08c1fe1c-b67c-4600-d2fe-b81fc31b3bf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54b9a9cffc3844789369754d0ce75101",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + Augmentation Random Order 2 ~ ImageNet-A\n",
            "24.306666666666665\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option3\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "####  RandomResizedCrop + RandomHorizontalFlip\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + Augmentation Random Order 2 ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_AugRandOrd_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + Augmentation Random Order ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6udgJyicmnuj",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "46875b24112f428e8c45a836a80caa2a"
          ]
        },
        "id": "6udgJyicmnuj",
        "outputId": "06441837-7202-4044-b6a0-07f85f1ef16c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46875b24112f428e8c45a836a80caa2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\n",
            "78.9\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option3\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RResizedCrop_HorFlip__ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fS6QSTDYY1dk",
      "metadata": {
        "id": "fS6QSTDYY1dk"
      },
      "source": [
        "#### RestNet50_V2 + MEMO ~ applied TTA + BN + Mixture of Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f098b94-8142-4345-bfa4-de8292c1207f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6c34ffe80cfe4224bcf741cff0029437"
          ]
        },
        "id": "4f098b94-8142-4345-bfa4-de8292c1207f",
        "outputId": "bb57f524-4cde-463c-f8f8-b43958139af5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c34ffe80cfe4224bcf741cff0029437",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + Mixture of Augmentations ~ ImageNet-A\n",
            "24.133333333333333\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option4\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "####  RandomResizedCrop + RandomHorizontalFlip\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + Mixture of Augmentations ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_MixtureAugs_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + Mixture of Augmentations ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5ebf99-09a6-4051-8a5f-b43fdec6f2ab",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "425ce355b3eb471b9d03b16a72c40c40"
          ]
        },
        "id": "3b5ebf99-09a6-4051-8a5f-b43fdec6f2ab",
        "outputId": "05090e97-b4e5-46fe-aa00-7989f214c248"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "425ce355b3eb471b9d03b16a72c40c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + Mixture of Augmentations ~ ImageNet-V2\n",
            "78.5\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option4\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + Mixture of Augmentations ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_MixtureAugs_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + Mixture of Augmentations ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m3kYvxOCp-yS",
      "metadata": {
        "id": "m3kYvxOCp-yS",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V2 + MEMO ~ applied TTA + BN + Sharpened Softmax Marginal Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UmZp690ngf5u",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "748ed8a014184d5db8831ebbe204c8a6"
          ]
        },
        "id": "UmZp690ngf5u",
        "outputId": "35d21a63-1869-4246-8e01-deb353278b0f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "748ed8a014184d5db8831ebbe204c8a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\n",
            "29.86666666666667\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             sharpened_softmax_entropy,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=TEMPERATURE,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RandomResizedCrop_SharpSoftMax_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e08110-08d0-4234-ad65-a360e4a48e36",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0308a24b80de49c8b6cde28220c10906"
          ]
        },
        "id": "64e08110-08d0-4234-ad65-a360e4a48e36",
        "outputId": "c6a1ce06-a258-4b85-ca87-dfaf8293d4c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0308a24b80de49c8b6cde28220c10906",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\n",
            "75.49\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             sharpened_softmax_entropy,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=TEMPERATURE,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RandomResizedCrop_SharpSoftMax_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yGAVE09MT0cD",
      "metadata": {
        "id": "yGAVE09MT0cD",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V2 + MEMO ~ applied TTA + BN + Augmentation Weigthed Marginal Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aZHnh_dmT4pR",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2726965e70b24094a740fe406cbad7d1"
          ]
        },
        "id": "aZHnh_dmT4pR",
        "outputId": "cf760aea-3612-4276-9c89-ac1cc0d14d10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2726965e70b24094a740fe406cbad7d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-A\n",
            "24.226666666666667\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             augmentation_weighted_entropy,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RandomResizedCrop_WeightedEntropy_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P1gZW1mcT_O6",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "75618605cd3a41ccba06a76282cad0a5"
          ]
        },
        "id": "P1gZW1mcT_O6",
        "outputId": "e87d1cc1-a172-4041-b86c-7f82ac1f423b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75618605cd3a41ccba06a76282cad0a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\n",
            "76.78\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'setup_experiment_logger' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_result)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43msetup_experiment_logger\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet50_V2_Memo_TTA_BN_RandomResizedCrop_WeightedEntropy_ImageNet-V2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'setup_experiment_logger' is not defined"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=True, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             augmentation_weighted_entropy,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V2_Memo_TTA_BN_RandomResizedCrop_WeightedEntropy_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V2 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AKxSPuBxosrb",
      "metadata": {
        "id": "AKxSPuBxosrb",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V1 + MEMO ~ applied TTA ~ RandomResizedCrop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zcQEDA12o9dw",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "63779fd7c2914dd989eab73bf1fecac9"
          ]
        },
        "id": "zcQEDA12o9dw",
        "outputId": "75adae9b-7e23-4e51-f9e8-b3908c6098b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63779fd7c2914dd989eab73bf1fecac9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-A\n",
            "3.6533333333333333\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_RandomResizedCrop_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + RandomResizedCrop ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cqG3YiCzpGrK",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ecf063663f61420ba32b22575da4a042"
          ]
        },
        "id": "cqG3YiCzpGrK",
        "outputId": "22c8d61e-a1af-4a6f-af66-e7b58693aa0d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecf063663f61420ba32b22575da4a042",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-V2\n",
            "69.03\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "evV4QBYnpLmR",
      "metadata": {
        "id": "evV4QBYnpLmR",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V1 + MEMO ~ applied TTA ~ RandomResizedCrop + BN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q5ssz_H8pOc2",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "59f7afa76e4b46d7a303044acb670292"
          ]
        },
        "id": "q5ssz_H8pOc2",
        "outputId": "b0c6f9f1-c3fc-4732-92de-4b2cbcfb392c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f7afa76e4b46d7a303044acb670292",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-A\n",
            "8.426666666666668\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A ###\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mLZqKNiSpbQz",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3eb44ac50e9e4bb68220473a8c5bd0d0"
          ]
        },
        "id": "mLZqKNiSpbQz",
        "outputId": "29b98c3e-e72c-4882-d2c2-54e836d6e657"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eb44ac50e9e4bb68220473a8c5bd0d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-V2\n",
            "68.2\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PKpaOg6Spnqn",
      "metadata": {
        "id": "PKpaOg6Spnqn",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_v1 + MEMO ~ applied TTA + BN + Multi Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2SlELI2upuMJ",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1e9106fc1d1f47378531688ce9644006"
          ]
        },
        "id": "2SlELI2upuMJ",
        "outputId": "4beeaa89-eb7d-497b-d4b4-b5706343c820"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e9106fc1d1f47378531688ce9644006",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + Augmentation Random Order 2 ~ ImageNet-A\n",
            "8.173333333333334\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option3\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "# RandomResizedCrop + RandomHorizontalFlip\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + Augmentation Random Order 2 ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_AugRandOrd_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + Augmentation Random Order ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P6yRB6xwpzUW",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9e1cd2dd486a4cb6a47d887e135ea743"
          ]
        },
        "id": "P6yRB6xwpzUW",
        "outputId": "f5ebad31-cdb7-41b0-e3d0-1f0021328d41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e1cd2dd486a4cb6a47d887e135ea743",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\n",
            "67.78999999999999\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option3\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RResizedCrop_HorFlip__ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x22Fu06NY7Zg",
      "metadata": {
        "id": "x22Fu06NY7Zg",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V1 + MEMO ~ applied TTA + BN + Mixture of Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JlrHZeOwZCYo",
      "metadata": {
        "id": "JlrHZeOwZCYo",
        "colab": {
          "referenced_widgets": [
            "570f9e2cdce04616bcdcea72dc4435f3"
          ]
        },
        "outputId": "792146f0-73d8-4d3f-d4f5-9f201dfdf3a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "570f9e2cdce04616bcdcea72dc4435f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + Mixture of Augmentations ~ ImageNet-A\n",
            "7.506666666666667\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option4\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "# RandomResizedCrop + RandomHorizontalFlip\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + Mixture of Augmentations ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_MixtureAugs_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + Mixture of Augmentations ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bTi_2LVtZRhk",
      "metadata": {
        "id": "bTi_2LVtZRhk",
        "colab": {
          "referenced_widgets": [
            "b9a58c4d79f7421dac439596d7249117"
          ]
        },
        "outputId": "b3c90dd0-1a48-44a8-9dac-86c2ede33335"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9a58c4d79f7421dac439596d7249117",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + Mixture of Augmentations ~ ImageNet-V2\n",
            "66.13\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option4\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + Mixture of Augmentations ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_MixtureAugs_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + Mixture of Augmentations ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bHG3W2UJp7Vs",
      "metadata": {
        "id": "bHG3W2UJp7Vs",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V1 + MEMO ~ applied TTA + BN + Sharpened Softmax Marginal Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yhCH6zBvp_DY",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3a942e999e514e9d96ac0eb36f76eb4d"
          ]
        },
        "id": "yhCH6zBvp_DY",
        "outputId": "2e2c3178-d101-4e9e-c326-eb93d95294b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a942e999e514e9d96ac0eb36f76eb4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\n",
            "4.84\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             sharpened_softmax_entropy,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=TEMPERATURE,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_SharpSoftMax_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac5be2e-cc33-4dac-92fb-be62fa432963",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "920dca4ee7fd4806b53758f739dab6b5"
          ]
        },
        "id": "7ac5be2e-cc33-4dac-92fb-be62fa432963",
        "outputId": "b16a836b-895c-458d-8a0a-5ce14c96492a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "920dca4ee7fd4806b53758f739dab6b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\n",
            "68.03\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             sharpened_softmax_entropy,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=TEMPERATURE,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_SharpSoftMax_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9hf_043yqNiV",
      "metadata": {
        "id": "9hf_043yqNiV",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### RestNet50_V1 + MEMO ~ applied TTA + BN + Augmentation Weigthed Marginal Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xm7mLuIAqS4n",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1611acbe5a59427a9a2713674eb44d18"
          ]
        },
        "id": "Xm7mLuIAqS4n",
        "outputId": "50177bc7-8766-492d-a17a-0431dbcce69a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1611acbe5a59427a9a2713674eb44d18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-A\n",
            "9.173333333333334\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#### ImageNet-A\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_a, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             augmentation_weighted_entropy,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_WeightedEntropy_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tv31Ycl0qVAu",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "bd28d819cd78442da01b6615a7447fcd"
          ]
        },
        "id": "tv31Ycl0qVAu",
        "outputId": "3caf3664-7ecb-429c-9739-6da5a5865119"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd28d819cd78442da01b6615a7447fcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\n",
            "68.8\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "ResNet, learning_rate, optimizer_resnet, data_loader_imagenet_v2, augmentations, preprocess = get_resnet_loader(is_default_weight=False, augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(ResNet,\n",
        "             learning_rate,\n",
        "             optimizer_resnet,\n",
        "             augmentation_weighted_entropy,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations,\n",
        "             prior_strenght_bn=PRIOR_STRENGTH,\n",
        "             apply_adaptive_bn=True,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"ResNet50_V1_Memo_TTA_BN_RandomResizedCrop_WeightedEntropy_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - ResNet50_V1 + BN + RandomResizedCrop + Augmentation Weighted Entropy ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hyTIXYTE5gzd",
      "metadata": {
        "id": "hyTIXYTE5gzd",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### VIT-B/16 + MEMO ~ RandomResizedCrop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1T_icX_in1gu",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "28f48259a1ae4af1a99e6c9bcce53ed6"
          ]
        },
        "id": "1T_icX_in1gu",
        "outputId": "936b0f47-8d00-45a9-d1ec-a3b5140fa119"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28f48259a1ae4af1a99e6c9bcce53ed6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop ~ ImageNet-A\n",
            "25.426666666666662\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, augmentations_vit, prepocess_vit = get_vit_loader(augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=prepocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RandomResizedCrop_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tfZTPrvUn7Es",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9ab0fc4b65fa46b3a48d6d447a7b4847"
          ]
        },
        "id": "tfZTPrvUn7Es",
        "outputId": "1cdad39b-689d-4d29-da5d-1fe162d5bae1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ab0fc4b65fa46b3a48d6d447a7b4847",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop ~ ImageNet-V2\n",
            "72.89999999999999\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RandomResizedCrop_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MZu2HYojoB-_",
      "metadata": {
        "id": "MZu2HYojoB-_",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### VIT-B/16 + MEMO ~ Multi Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZxXbZ5FYoEy_",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ea0705742e3546249051570b2895ee42"
          ]
        },
        "id": "ZxXbZ5FYoEy_",
        "outputId": "d366a662-74e8-4dbf-99c9-3cdc629adb47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea0705742e3546249051570b2895ee42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-A\n",
            "24.973333333333333\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'setup_experiment_logger' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_result)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43msetup_experiment_logger\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIT-B16_V1_Memo_TTA_RResizedCrop_HorFlip_ImageNet-A\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-A\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'setup_experiment_logger' is not defined"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option3\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RResizedCrop_HorFlip_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G7SLRLSboMz-",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "edf2ed17e255435683e64ff66e0d0baa"
          ]
        },
        "id": "G7SLRLSboMz-",
        "outputId": "d655035e-5cb3-4928-a6b1-d309fadaa525"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edf2ed17e255435683e64ff66e0d0baa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\n",
            "72.84\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option3\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RResizedCrop_HorFlip_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + RandomHorizontalFlip ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63TDLBZ4Y-fZ",
      "metadata": {
        "id": "63TDLBZ4Y-fZ"
      },
      "source": [
        "#### VIT-B/16 + MEMO ~ Mixture of Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaae9321-c2e7-4710-87a0-d154c6f6ea23",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5a73a90b249346b1a122e6aea9ec7c54"
          ]
        },
        "id": "aaae9321-c2e7-4710-87a0-d154c6f6ea23",
        "outputId": "0ecfb0cb-d419-46ad-a5d8-f366e9632817"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a73a90b249346b1a122e6aea9ec7c54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + Mixture of Augmentations ~ ImageNet-A\n",
            "24.493333333333332\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option4\", is_imgnet_a=True)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             marginal_entropy_loss,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + Mixture of Augmentations ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_MixtureAugs_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + Mixture of Augmentations ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e8668c-ec50-4128-b079-cb19877f2478",
      "metadata": {
        "id": "61e8668c-ec50-4128-b079-cb19877f2478"
      },
      "outputs": [],
      "source": [
        "# ImageNet-V2\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option4\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             marginal_entropy_loss,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + Mixture of Augmentations ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_MixtureAugs_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + Mixture of Augmentations ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9Rc5M30eokv4",
      "metadata": {
        "id": "9Rc5M30eokv4",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### VIT-B/16 + MEMO ~ applied TTA + BN + Sharpened Softmax Marginal Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KTZ2eoLCopbU",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f58fb8d5fcbf41b5b0a5b8957e4f5038"
          ]
        },
        "id": "KTZ2eoLCopbU",
        "outputId": "935ca479-45c2-4f0c-cdfa-cb099104dfd4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f58fb8d5fcbf41b5b0a5b8957e4f5038",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Sharpened Softmax ~ ImageNet-A\n",
            "23.42666666666667\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             sharpened_softmax_entropy,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=0.5,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Sharpened Softmax ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RandomResizedCrop_SharpSoftMax_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wVlrzgudoqNT",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ed9dc197f1d044cfaf44216b7667c829"
          ]
        },
        "id": "wVlrzgudoqNT",
        "outputId": "58f4188b-a746-41c9-df1f-a0508d1a438a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed9dc197f1d044cfaf44216b7667c829",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\n",
            "72.3\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             sharpened_softmax_entropy,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=TEMPERATURE,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RandomResizedCrop_SharpSoftMax_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Sharpened Softmax Entropy ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49L70y_9UZ_U",
      "metadata": {
        "id": "49L70y_9UZ_U",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### VIT-B/16 + MEMO ~ applied TTA + BN + Augmentation Weigthed Marginal Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1vcXkEZ8Udr7",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3f1b6767d676422a92b4db82c272cbbf"
          ]
        },
        "id": "1vcXkEZ8Udr7",
        "outputId": "803c4cd0-120b-4895-cfd0-5c2fd63a14ef"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f1b6767d676422a92b4db82c272cbbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Augmentation Weigthed Entropy ~ ImageNet-A\n",
            "25.173333333333332\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-A\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_a_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option2\", is_imgnet_a=True)\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             augmentation_weighted_entropy,\n",
        "             indices_in_1k,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_a_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Augmentation Weigthed Entropy ~ ImageNet-A\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RandomResizedCrop_WeigthedEntropy_ImageNet-A\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Augmentation Weigthed Entropy ~ ImageNet-A\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3qYfRaIPUkDw",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "484331be0e714cc4ab22ba13de5543b0"
          ]
        },
        "id": "3qYfRaIPUkDw",
        "outputId": "a5ce94b0-db03-4abc-c6e0-9feb6677305e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "484331be0e714cc4ab22ba13de5543b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Augmentation Weigthed Entropy ~ ImageNet-V2\n",
            "72.82\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ImageNet-V2\n",
        "VIT_V1, learning_rate, optimizer_vit, data_loader_imagenet_v2_vit, augmentations_vit, preprocess_vit = get_vit_loader(augmentation_option=\"option2\", is_imgnet_a=False)\n",
        "\n",
        "model = MEMO(VIT_V1,\n",
        "             learning_rate,\n",
        "             optimizer_vit,\n",
        "             augmentation_weighted_entropy,\n",
        "             imagenet_v_mask,\n",
        "             apply_tta=True,\n",
        "             augmentations=augmentations_vit,\n",
        "             prior_strenght_bn=None,\n",
        "             apply_adaptive_bn=False,\n",
        "             temperature=None,\n",
        "             apply_transform=True,\n",
        "             preprocess=preprocess_vit)\n",
        "\n",
        "test_result = test_model_tta_applied(model, data_loader_imagenet_v2_vit)\n",
        "\n",
        "print(\"\\nResult: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Augmentation Weigthed Entropy ~ ImageNet-V2\")\n",
        "print(test_result)\n",
        "print('\\n')\n",
        "\n",
        "logger = setup_experiment_logger(\"experiment_logs\", \"VIT-B16_V1_Memo_TTA_RandomResizedCrop_WeigthedEntropy_ImageNet-V2\")\n",
        "logger.info(\"Result: MEMO ~ TTA - VIT-B/16_V1 + RandomResizedCrop + Augmentation Weigthed Entropy ~ ImageNet-V2\")\n",
        "logger.info(f\"{test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oxizWcZ2_tMc",
      "metadata": {
        "id": "oxizWcZ2_tMc"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e62ca95-6f42-43cf-b783-82e008a30b2d",
      "metadata": {
        "id": "4e62ca95-6f42-43cf-b783-82e008a30b2d"
      },
      "source": [
        "The following tables show the top-1 accuracy (%) of the model on ImageNet-A and ImageNet-V2 datasets using various combinations of MEMO with Batch Normalization,  different choices of augmentation techniques, and entropy configuration approaches where the test time adaptation method is applied, ResNet50 and Vit-B/16 as a backbone model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k2-u5dV1qd7j",
      "metadata": {
        "id": "k2-u5dV1qd7j"
      },
      "source": [
        "|  Test Result with ResNet50 with weight V1  | ImageNet-A | ImageNet-V2 |\n",
        "|-----|:------------:|:-------------:|\n",
        "|                            Baseline                       | 0.03 | 63.15 |\n",
        "| +MEMO (RandomResizedCrop) | 3.65  | **69.03** |\n",
        "| +MEMO + BN (RandomResizedCrop) | 8.43  | 68.2 |\n",
        "| +MEMO + BN (RandomResizedCrop) + Sharpened SoftMax Marginal Entropy | 4.84| 68.03 |\n",
        "| +MEMO + BN (RandomResizedCrop) + Augmentation Weighted Marginal Entropy | **9.17** | 68.80 |\n",
        "| +MEMO + BN (RandomResizedCrop + RandomHorizontalFlip) | 8.17 | 67.79 |\n",
        "| +MEMO + BN (RandomResizedCrop + RandomAffine + RandomPerspective + RandomHorizontalFlip) | 7.51 | 66.13 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h4dg4MmXJi8D",
      "metadata": {
        "id": "h4dg4MmXJi8D"
      },
      "source": [
        "| Test Result with ResNet50 with weight V2| ImageNet-A | ImageNet-V2 |\n",
        "|-----|:------------:|:-------------:|\n",
        "| Baseline | 14.27 | 69.89 |\n",
        "| +MEMO (RandomResizedCrop) | 18.41  | 76.03 |\n",
        "| +MEMO + BN (RandomResizedCrop) | 24.24  | 78.69 |\n",
        "| +MEMO + BN (RandomResizedCrop) + Sharpened SoftMax Marginal Entropy | **29.87** | 75.49 |\n",
        "| +MEMO + BN (RandomResizedCrop) + Augmentation Weighted Marginal Entropy | 24.22 | 76.78 |\n",
        "| +MEMO + BN (RandomResizedCrop + RandomHorizontalFlip) | 24.31 | **78.90** |\n",
        "| +MEMO + BN (RandomResizedCrop + RandomAffine + RandomPerspective + RandomHorizontalFlip) | 24.13 | 78.5 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SA57D1eFiglD",
      "metadata": {
        "id": "SA57D1eFiglD"
      },
      "source": [
        "| Test Result with Vit-B/16 | ImageNet-A | ImageNet-V2|\n",
        "|-----|:------------:|:------------:|\n",
        "| Baseline| 20.75 | 69.57 |\n",
        "| +MEMO (RandomResizedCrop) | **25.43** | **72.90** |\n",
        "| +MEMO (RandomResizedCrop) + Sharpened SoftMax Marginal Entropy| 23.43 | 72.30 |\n",
        "| +MEMO (RandomResizedCrop) + Augmentation Weighted Marginal Entropy| 25.17 | 72.82 |\n",
        "| +MEMO (RandomResizedCrop + RandomHorizontalFlip)| 24.97 | 72.84 |\n",
        "| +MEMO (RandomResizedCrop + RandomAffine + RandomPerspective + RandomHorizontalFlip) | 24.49 | __ |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c23c59f-aae2-42b0-a302-28a2125ac01d",
      "metadata": {
        "id": "0c23c59f-aae2-42b0-a302-28a2125ac01d"
      },
      "source": [
        "### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ad423f-eaa8-4d73-90ac-08118479bdfb",
      "metadata": {
        "id": "a6ad423f-eaa8-4d73-90ac-08118479bdfb"
      },
      "source": [
        "Due to the large amount of time required to keep the experiment minimal, I limited the augmentation number to 32, although it was ideal to set it to 64, as suggested in the MEMO paper. Nevertheless, my modicaitons did improve the baseline performance, which achieved without applying any TTA method. Also for the same reason, I haven't included AugMix as an option to apply as an augmentation; however, one experiment was done with AugMix, but it was taking more than 4 hours, and the result was not competitive with others; therefore, I avoided including AugMix augmentation choice in the modification.\n",
        "\n",
        "From the results of ResNet50 with weight differences, the new weight V2 has improved performance on both ImageNet-A and ImageNet-V2.\n",
        "\n",
        "For the Vit.B/16 model, the performance outperforms the baseline, yet it does not surpass that of ResNet50 as a backbone. Unfortunately, none of the other modifications to the model could outperform the model using only RandomResizedCrop as an augmentation method, even though all outperformed the baseline with noticeably higher accuracy.\n",
        "\n",
        "**Adaptive Batch Normalization**\n",
        "\n",
        "As the MEMO paper suggested, I inserted the technique into the model that has ResNet50 as a backbone, with the same expectation that the tweaked model's performance would be improved on both datasets; therefore, the subsequent modifications were made all with a BN layer, except for models based on Vit-B/16.\n",
        "\n",
        "**Sharpened softmax marginal entropy**\n",
        "\n",
        "This tweaking approach improved the ResNet-50 (weight V1) as the backbone of the model on ImageNet-A, yielding the best accuracy result **29.87 (+15.6)**.\n",
        "\n",
        "**Augmentation weighted marginal entropy**\n",
        "\n",
        "Instead, this modification to the entropy computation approach improved the ResNet-50 (weight V1) as the backbone of the model on ImageNet-A, yielding the best accuracy result **9.17 (+9.14)**. Also, for ImageNet-V2, the modification has given the $2^{\\text{nd}}$ best result **68.80 (+6.65)**.\n",
        "\n",
        "\n",
        "**RandomResizedCrop**\n",
        "\n",
        "This augmentation choice was used for the previous two modifications as it has given slightly less but relatively stable accuracy results. Additionally, for Vit-B/16 as the backbone of the model in both ImageNet-A and ImageNet-V2, it has yielded the best results, **25.43 (+4.68)** and **72.90 (+3.33)**, respectively.\n",
        "\n",
        "\n",
        "**RandomResizedCrop + RandomHorizontalFlip**\n",
        "\n",
        "As the MEMO paper has witnessed the improvement using the horizontal flip standard augmentation method, I implemented it for ResNet50 (weight V2) as the backbone of the model for ImageNet-V2, which gave the best result, **78.90 (+9.01)** accuracy.\n",
        "\n",
        "\n",
        "**RandomResizedCrop + RandomAffine + RandomPerspective + RandomHorizontalFlip**\n",
        "\n",
        "As a trial of alternating the augmentation methods, I used these combination of augmentation methods to improve the performance. This method outperformemed all the baselines on both datasets, however the results were slighly less than using the RandomResizedCrop + RandomHorizontalFlip combination.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56af90ce-84cf-4d2c-8ced-6d3297ad704c",
      "metadata": {
        "id": "56af90ce-84cf-4d2c-8ced-6d3297ad704c"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b97b47f3-fe9f-48a9-99e3-f2bcd6e42170",
      "metadata": {
        "id": "b97b47f3-fe9f-48a9-99e3-f2bcd6e42170"
      },
      "source": [
        "This project shows that MEMO improved the pre-trained model through marginal entropy minimization with a one-test-point approach. Additionally, slight modifications to how softmax and entropy are computed also enhanced the model’s performance on the classification task. Using different augmentation techniques had limited potential to improve classification accuracy. However, due to the sharp distribution shift in the test dataset—especially in ImageNet-A—neither augmentation nor model adjustments led to a significant performance improvement even though they outperformed all the baselines. Therefore, it is reasonable to conclude that the MEMO method is effective for test-time adaptation, especially in scenarios with distribution shift, even when only a single test sample is available at a time, although further tuning and adaptation steps, or model components may be necessary to achieve optimal performance,"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UIuL14nsCFDE",
        "9c71f116",
        "L27FxuSyUi98",
        "29e1cbdd",
        "3d6a76b1",
        "lWRomNvAKgDX",
        "0i8-PSkGKl0q",
        "iGcKXIxC6pRS",
        "kgrnzhTPSDsH",
        "1ee10c95-361a-4be3-b03a-cf08a7eeeb30",
        "MYM8eZOT6Jw4",
        "14b2c722",
        "390fe426-5d07-49c5-b8e0-d255fd5489d6",
        "1SrIp2sxEvhU",
        "KHy89o9ikAKT",
        "aGnmNP_3f_r0",
        "m3kYvxOCp-yS",
        "yGAVE09MT0cD",
        "AKxSPuBxosrb",
        "evV4QBYnpLmR",
        "bHG3W2UJp7Vs",
        "9hf_043yqNiV",
        "hyTIXYTE5gzd",
        "MZu2HYojoB-_",
        "9Rc5M30eokv4",
        "49L70y_9UZ_U"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "285429ef03b248dba822822334166da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "365e21074905465584ec1dc7568bd8c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399bedc9fd7c4a58b08dd0b2270ca7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47f2df8481c2421fb6b994a79d5dbb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7989acae16d453ba40ca5d350207779",
            "placeholder": "​",
            "style": "IPY_MODEL_52dca400e0dd4182ac6ae333b98881d4",
            "value": "  0%"
          }
        },
        "4cf96421b88c43748ad95bf6686829b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edda447619f4dc58392a6bc019418fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52dca400e0dd4182ac6ae333b98881d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52faa556b795487f9e1920b0c9fb61cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47f2df8481c2421fb6b994a79d5dbb22",
              "IPY_MODEL_7ae0d14232324444a4779276e5393c44",
              "IPY_MODEL_77632b65724b42fb8e57b04bf73253bf"
            ],
            "layout": "IPY_MODEL_8ea1e6d147e34ea8b3344199a913674d"
          }
        },
        "57a9725dd4384351bbc4884919b5ae2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d985f88754947cf8f660e39102e1d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23ab46c7bee44e7bd5d0ce72aad5d9e",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90dee414cd0640baad015dcfd4b84d52",
            "value": 0
          }
        },
        "77632b65724b42fb8e57b04bf73253bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edda447619f4dc58392a6bc019418fe",
            "placeholder": "​",
            "style": "IPY_MODEL_c699a95d7c0d464692a347a8e89ccd67",
            "value": " 10/7500 [00:02&lt;28:29,  4.38it/s]"
          }
        },
        "7ae0d14232324444a4779276e5393c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf96421b88c43748ad95bf6686829b7",
            "max": 7500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_399bedc9fd7c4a58b08dd0b2270ca7bb",
            "value": 10
          }
        },
        "7f068021cc4342fa8136bc02f9b728c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_365e21074905465584ec1dc7568bd8c1",
            "placeholder": "​",
            "style": "IPY_MODEL_a4a918f7fd7343bf8364c7136a91ffb0",
            "value": "  0%"
          }
        },
        "8ea1e6d147e34ea8b3344199a913674d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90dee414cd0640baad015dcfd4b84d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "928446f9025e41ad8d5557bf10eb77d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a918f7fd7343bf8364c7136a91ffb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c699a95d7c0d464692a347a8e89ccd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7989acae16d453ba40ca5d350207779": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f068baf60f4a0bbbc27a57e63bbfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a9725dd4384351bbc4884919b5ae2f",
            "placeholder": "​",
            "style": "IPY_MODEL_285429ef03b248dba822822334166da4",
            "value": " 0/10000 [00:00&lt;?, ?it/s]"
          }
        },
        "e23ab46c7bee44e7bd5d0ce72aad5d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c2d70b6a994b2e8ec5e7bef7f8dbfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f068021cc4342fa8136bc02f9b728c5",
              "IPY_MODEL_5d985f88754947cf8f660e39102e1d6b",
              "IPY_MODEL_d1f068baf60f4a0bbbc27a57e63bbfc9"
            ],
            "layout": "IPY_MODEL_928446f9025e41ad8d5557bf10eb77d1"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}